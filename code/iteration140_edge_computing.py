#!/usr/bin/env python3
"""
Server Init - Iteration 140: Edge Computing Platform
ÐŸÐ»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð° Edge Computing

Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»:
- Edge Node Management - ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ edge ÑƒÐ·Ð»Ð°Ð¼Ð¸
- Workload Distribution - Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
- Data Synchronization - ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…
- Offline Mode - Ð¾Ñ„Ð»Ð°Ð¹Ð½ Ñ€ÐµÐ¶Ð¸Ð¼
- Latency Optimization - Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ¸
- Resource Constraints - Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
- Fleet Management - ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ„Ð»Ð¾Ñ‚Ð¾Ð¼
- Edge Analytics - Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° Ð½Ð° edge
"""

import json
import asyncio
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Set
from enum import Enum
from collections import defaultdict
import uuid
import random


class NodeStatus(Enum):
    """Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑƒÐ·Ð»Ð°"""
    ONLINE = "online"
    OFFLINE = "offline"
    DEGRADED = "degraded"
    MAINTENANCE = "maintenance"
    PROVISIONING = "provisioning"


class SyncStatus(Enum):
    """Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸"""
    SYNCED = "synced"
    SYNCING = "syncing"
    OUT_OF_SYNC = "out_of_sync"
    CONFLICT = "conflict"


class WorkloadType(Enum):
    """Ð¢Ð¸Ð¿ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
    CONTAINER = "container"
    FUNCTION = "function"
    ML_MODEL = "ml_model"
    DATA_PIPELINE = "data_pipeline"


class ResourceType(Enum):
    """Ð¢Ð¸Ð¿ Ñ€ÐµÑÑƒÑ€ÑÐ°"""
    CPU = "cpu"
    MEMORY = "memory"
    STORAGE = "storage"
    GPU = "gpu"
    NETWORK = "network"


@dataclass
class ResourceSpec:
    """Ð¡Ð¿ÐµÑ†Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²"""
    cpu_cores: float = 1.0
    memory_mb: int = 512
    storage_mb: int = 1024
    gpu_count: int = 0
    network_mbps: int = 100


@dataclass
class EdgeNode:
    """Edge ÑƒÐ·ÐµÐ»"""
    node_id: str
    name: str = ""
    
    # Location
    location: str = ""
    region: str = ""
    latitude: float = 0.0
    longitude: float = 0.0
    
    # Status
    status: NodeStatus = NodeStatus.OFFLINE
    sync_status: SyncStatus = SyncStatus.OUT_OF_SYNC
    
    # Resources
    total_resources: ResourceSpec = field(default_factory=ResourceSpec)
    available_resources: ResourceSpec = field(default_factory=ResourceSpec)
    
    # Connectivity
    connected: bool = False
    last_heartbeat: Optional[datetime] = None
    latency_ms: float = 0.0
    
    # Workloads
    workload_count: int = 0
    
    # Metadata
    labels: Dict = field(default_factory=dict)
    tags: List[str] = field(default_factory=list)
    
    # Timestamps
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class Workload:
    """ÐÐ°Ð³Ñ€ÑƒÐ·ÐºÐ°"""
    workload_id: str
    name: str = ""
    
    # Type
    workload_type: WorkloadType = WorkloadType.CONTAINER
    
    # Image/Config
    image: str = ""
    config: Dict = field(default_factory=dict)
    
    # Resources
    required_resources: ResourceSpec = field(default_factory=ResourceSpec)
    
    # Placement
    target_nodes: List[str] = field(default_factory=list)
    deployed_nodes: List[str] = field(default_factory=list)
    
    # Status
    status: str = "pending"  # pending, deploying, running, failed
    replicas: int = 1
    ready_replicas: int = 0
    
    # Priority
    priority: int = 5  # 1-10
    
    # Timestamps
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class DataSync:
    """Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    sync_id: str
    node_id: str = ""
    
    # Data
    data_type: str = ""
    data_size_bytes: int = 0
    
    # Status
    status: SyncStatus = SyncStatus.OUT_OF_SYNC
    
    # Progress
    progress_percent: float = 0.0
    
    # Timestamps
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    last_sync: Optional[datetime] = None


@dataclass
class EdgeAnalytics:
    """ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° Edge"""
    analytics_id: str
    node_id: str = ""
    
    # Metrics
    requests_per_second: float = 0.0
    avg_latency_ms: float = 0.0
    error_rate: float = 0.0
    
    # Resources
    cpu_utilization: float = 0.0
    memory_utilization: float = 0.0
    network_in_mbps: float = 0.0
    network_out_mbps: float = 0.0
    
    # Period
    timestamp: datetime = field(default_factory=datetime.now)
    period_seconds: int = 60


@dataclass
class Fleet:
    """Ð¤Ð»Ð¾Ñ‚"""
    fleet_id: str
    name: str = ""
    
    # Nodes
    node_ids: List[str] = field(default_factory=list)
    
    # Config
    default_workloads: List[str] = field(default_factory=list)
    
    # Labels
    selector: Dict = field(default_factory=dict)
    
    # Stats
    total_nodes: int = 0
    online_nodes: int = 0


class NodeManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ ÑƒÐ·Ð»Ð¾Ð²"""
    
    def __init__(self):
        self.nodes: Dict[str, EdgeNode] = {}
        
    def register(self, name: str, location: str, region: str,
                  resources: ResourceSpec = None, **kwargs) -> EdgeNode:
        """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑƒÐ·Ð»Ð°"""
        res = resources or ResourceSpec()
        
        node = EdgeNode(
            node_id=f"node_{uuid.uuid4().hex[:8]}",
            name=name,
            location=location,
            region=region,
            status=NodeStatus.PROVISIONING,
            total_resources=res,
            available_resources=ResourceSpec(
                cpu_cores=res.cpu_cores,
                memory_mb=res.memory_mb,
                storage_mb=res.storage_mb,
                gpu_count=res.gpu_count,
                network_mbps=res.network_mbps
            ),
            **kwargs
        )
        
        self.nodes[node.node_id] = node
        return node
        
    def update_status(self, node_id: str, status: NodeStatus) -> EdgeNode:
        """ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°"""
        node = self.nodes.get(node_id)
        if node:
            node.status = status
            if status == NodeStatus.ONLINE:
                node.connected = True
                node.last_heartbeat = datetime.now()
        return node
        
    async def heartbeat(self, node_id: str, metrics: Dict = None) -> Dict:
        """Heartbeat"""
        node = self.nodes.get(node_id)
        if not node:
            return {"error": "Node not found"}
            
        node.last_heartbeat = datetime.now()
        node.connected = True
        
        if metrics:
            node.latency_ms = metrics.get("latency_ms", 0)
            
        return {
            "node_id": node_id,
            "status": node.status.value,
            "heartbeat": node.last_heartbeat.isoformat()
        }
        
    def get_online_nodes(self, region: str = None) -> List[EdgeNode]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ð½Ð»Ð°Ð¹Ð½ ÑƒÐ·Ð»Ð¾Ð²"""
        nodes = [n for n in self.nodes.values() if n.status == NodeStatus.ONLINE]
        if region:
            nodes = [n for n in nodes if n.region == region]
        return nodes
        
    def check_offline_nodes(self, timeout_seconds: int = 60) -> List[EdgeNode]:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¾Ñ„Ð»Ð°Ð¹Ð½ ÑƒÐ·Ð»Ð¾Ð²"""
        offline = []
        now = datetime.now()
        
        for node in self.nodes.values():
            if node.last_heartbeat:
                if (now - node.last_heartbeat).total_seconds() > timeout_seconds:
                    node.status = NodeStatus.OFFLINE
                    node.connected = False
                    offline.append(node)
                    
        return offline


class WorkloadScheduler:
    """ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
    
    def __init__(self, node_manager: NodeManager):
        self.node_manager = node_manager
        self.workloads: Dict[str, Workload] = {}
        
    def create(self, name: str, workload_type: WorkloadType,
                image: str, resources: ResourceSpec = None,
                replicas: int = 1, **kwargs) -> Workload:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
        workload = Workload(
            workload_id=f"workload_{uuid.uuid4().hex[:8]}",
            name=name,
            workload_type=workload_type,
            image=image,
            required_resources=resources or ResourceSpec(),
            replicas=replicas,
            **kwargs
        )
        
        self.workloads[workload.workload_id] = workload
        return workload
        
    async def schedule(self, workload_id: str, target_nodes: List[str] = None,
                        selector: Dict = None) -> Dict:
        """ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
        workload = self.workloads.get(workload_id)
        if not workload:
            return {"error": "Workload not found"}
            
        # Find target nodes
        if target_nodes:
            nodes = [self.node_manager.nodes[nid] for nid in target_nodes 
                    if nid in self.node_manager.nodes]
        elif selector:
            nodes = self._select_nodes(selector)
        else:
            nodes = self.node_manager.get_online_nodes()
            
        # Filter by resources
        suitable_nodes = []
        for node in nodes:
            if self._can_fit(node, workload.required_resources):
                suitable_nodes.append(node)
                
        if not suitable_nodes:
            return {"error": "No suitable nodes found"}
            
        # Schedule
        workload.status = "deploying"
        workload.target_nodes = [n.node_id for n in suitable_nodes[:workload.replicas]]
        
        # Simulate deployment
        await asyncio.sleep(0.1)
        
        for node_id in workload.target_nodes:
            node = self.node_manager.nodes.get(node_id)
            if node:
                # Reserve resources
                node.available_resources.cpu_cores -= workload.required_resources.cpu_cores
                node.available_resources.memory_mb -= workload.required_resources.memory_mb
                node.workload_count += 1
                workload.deployed_nodes.append(node_id)
                workload.ready_replicas += 1
                
        workload.status = "running"
        
        return {
            "workload_id": workload_id,
            "status": workload.status,
            "deployed_nodes": workload.deployed_nodes,
            "ready_replicas": workload.ready_replicas
        }
        
    def _select_nodes(self, selector: Dict) -> List[EdgeNode]:
        """Ð’Ñ‹Ð±Ð¾Ñ€ ÑƒÐ·Ð»Ð¾Ð² Ð¿Ð¾ ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€Ñƒ"""
        nodes = []
        for node in self.node_manager.nodes.values():
            if node.status != NodeStatus.ONLINE:
                continue
            match = all(node.labels.get(k) == v for k, v in selector.items())
            if match:
                nodes.append(node)
        return nodes
        
    def _can_fit(self, node: EdgeNode, resources: ResourceSpec) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²"""
        return (node.available_resources.cpu_cores >= resources.cpu_cores and
                node.available_resources.memory_mb >= resources.memory_mb and
                node.available_resources.storage_mb >= resources.storage_mb)


class DataSyncManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    
    def __init__(self, node_manager: NodeManager):
        self.node_manager = node_manager
        self.syncs: Dict[str, DataSync] = {}
        
    async def sync(self, node_id: str, data_type: str,
                    data_size_bytes: int) -> DataSync:
        """Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        node = self.node_manager.nodes.get(node_id)
        if not node:
            return None
            
        sync = DataSync(
            sync_id=f"sync_{uuid.uuid4().hex[:8]}",
            node_id=node_id,
            data_type=data_type,
            data_size_bytes=data_size_bytes,
            status=SyncStatus.SYNCING,
            started_at=datetime.now()
        )
        
        self.syncs[sync.sync_id] = sync
        
        # Simulate sync progress
        for progress in [25, 50, 75, 100]:
            await asyncio.sleep(0.05)
            sync.progress_percent = progress
            
        sync.status = SyncStatus.SYNCED
        sync.completed_at = datetime.now()
        sync.last_sync = datetime.now()
        
        node.sync_status = SyncStatus.SYNCED
        
        return sync
        
    def get_sync_status(self, node_id: str) -> List[DataSync]:
        """Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑƒÐ·Ð»Ð°"""
        return [s for s in self.syncs.values() if s.node_id == node_id]


class EdgeAnalyticsEngine:
    """Ð”Ð²Ð¸Ð¶Ð¾Ðº Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Edge"""
    
    def __init__(self, node_manager: NodeManager):
        self.node_manager = node_manager
        self.analytics: Dict[str, List[EdgeAnalytics]] = defaultdict(list)
        
    def collect(self, node_id: str) -> EdgeAnalytics:
        """Ð¡Ð±Ð¾Ñ€ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸"""
        node = self.node_manager.nodes.get(node_id)
        if not node:
            return None
            
        analytics = EdgeAnalytics(
            analytics_id=f"analytics_{uuid.uuid4().hex[:8]}",
            node_id=node_id,
            requests_per_second=random.uniform(10, 1000),
            avg_latency_ms=random.uniform(1, 50),
            error_rate=random.uniform(0, 0.05),
            cpu_utilization=random.uniform(0.2, 0.8),
            memory_utilization=random.uniform(0.3, 0.9),
            network_in_mbps=random.uniform(1, 100),
            network_out_mbps=random.uniform(1, 50)
        )
        
        self.analytics[node_id].append(analytics)
        
        # Keep last 100
        if len(self.analytics[node_id]) > 100:
            self.analytics[node_id] = self.analytics[node_id][-100:]
            
        return analytics
        
    def get_aggregate(self, node_ids: List[str] = None) -> Dict:
        """ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ°"""
        if node_ids:
            nodes_analytics = [self.analytics[nid] for nid in node_ids if nid in self.analytics]
        else:
            nodes_analytics = list(self.analytics.values())
            
        if not nodes_analytics:
            return {}
            
        all_metrics = [a for node_list in nodes_analytics for a in node_list]
        
        if not all_metrics:
            return {}
            
        return {
            "avg_rps": sum(a.requests_per_second for a in all_metrics) / len(all_metrics),
            "avg_latency_ms": sum(a.avg_latency_ms for a in all_metrics) / len(all_metrics),
            "avg_error_rate": sum(a.error_rate for a in all_metrics) / len(all_metrics),
            "avg_cpu": sum(a.cpu_utilization for a in all_metrics) / len(all_metrics),
            "avg_memory": sum(a.memory_utilization for a in all_metrics) / len(all_metrics),
            "total_samples": len(all_metrics)
        }


class FleetManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ñ„Ð»Ð¾Ñ‚Ð°"""
    
    def __init__(self, node_manager: NodeManager):
        self.node_manager = node_manager
        self.fleets: Dict[str, Fleet] = {}
        
    def create(self, name: str, selector: Dict = None) -> Fleet:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ„Ð»Ð¾Ñ‚Ð°"""
        fleet = Fleet(
            fleet_id=f"fleet_{uuid.uuid4().hex[:8]}",
            name=name,
            selector=selector or {}
        )
        
        # Find matching nodes
        if selector:
            for node in self.node_manager.nodes.values():
                if all(node.labels.get(k) == v for k, v in selector.items()):
                    fleet.node_ids.append(node.node_id)
        else:
            fleet.node_ids = list(self.node_manager.nodes.keys())
            
        fleet.total_nodes = len(fleet.node_ids)
        fleet.online_nodes = len([
            nid for nid in fleet.node_ids 
            if self.node_manager.nodes[nid].status == NodeStatus.ONLINE
        ])
        
        self.fleets[fleet.fleet_id] = fleet
        return fleet
        
    def update_fleet_status(self):
        """ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ñ„Ð»Ð¾Ñ‚Ð¾Ð²"""
        for fleet in self.fleets.values():
            fleet.total_nodes = len(fleet.node_ids)
            fleet.online_nodes = len([
                nid for nid in fleet.node_ids
                if nid in self.node_manager.nodes and
                self.node_manager.nodes[nid].status == NodeStatus.ONLINE
            ])


class EdgeComputingPlatform:
    """ÐŸÐ»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð° Edge Computing"""
    
    def __init__(self):
        self.node_manager = NodeManager()
        self.scheduler = WorkloadScheduler(self.node_manager)
        self.sync_manager = DataSyncManager(self.node_manager)
        self.analytics = EdgeAnalyticsEngine(self.node_manager)
        self.fleet_manager = FleetManager(self.node_manager)
        
    def get_statistics(self) -> Dict[str, Any]:
        """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°"""
        nodes = list(self.node_manager.nodes.values())
        workloads = list(self.scheduler.workloads.values())
        
        return {
            "total_nodes": len(nodes),
            "online_nodes": len([n for n in nodes if n.status == NodeStatus.ONLINE]),
            "offline_nodes": len([n for n in nodes if n.status == NodeStatus.OFFLINE]),
            "workloads": len(workloads),
            "running_workloads": len([w for w in workloads if w.status == "running"]),
            "fleets": len(self.fleet_manager.fleets),
            "syncs": len(self.sync_manager.syncs),
            "regions": len(set(n.region for n in nodes))
        }


# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ
if __name__ == "__main__":
    print("=" * 60)
    print("Server Init - Iteration 140: Edge Computing Platform")
    print("=" * 60)
    
    async def demo():
        platform = EdgeComputingPlatform()
        print("âœ“ Edge Computing Platform created")
        
        # Register edge nodes
        print("\nðŸ–¥ï¸ Registering Edge Nodes...")
        
        nodes_config = [
            ("edge-nyc-01", "New York", "us-east", ResourceSpec(cpu_cores=4, memory_mb=8192, storage_mb=51200), {"environment": "production", "tier": "tier1"}),
            ("edge-nyc-02", "New York", "us-east", ResourceSpec(cpu_cores=4, memory_mb=8192, storage_mb=51200), {"environment": "production", "tier": "tier1"}),
            ("edge-la-01", "Los Angeles", "us-west", ResourceSpec(cpu_cores=2, memory_mb=4096, storage_mb=25600), {"environment": "production", "tier": "tier2"}),
            ("edge-london-01", "London", "eu-west", ResourceSpec(cpu_cores=4, memory_mb=16384, storage_mb=102400), {"environment": "production", "tier": "tier1"}),
            ("edge-tokyo-01", "Tokyo", "ap-northeast", ResourceSpec(cpu_cores=8, memory_mb=32768, storage_mb=204800, gpu_count=1), {"environment": "production", "tier": "tier1"}),
            ("edge-sydney-01", "Sydney", "ap-southeast", ResourceSpec(cpu_cores=2, memory_mb=4096, storage_mb=25600), {"environment": "staging", "tier": "tier2"})
        ]
        
        created_nodes = []
        for name, location, region, resources, labels in nodes_config:
            node = platform.node_manager.register(
                name, location, region, resources,
                labels=labels,
                tags=["edge", region]
            )
            created_nodes.append(node)
            print(f"  âœ“ {name} ({region}): {resources.cpu_cores} CPU, {resources.memory_mb}MB RAM")
            
        # Bring nodes online
        print("\nðŸŸ¢ Bringing Nodes Online...")
        
        for node in created_nodes[:-1]:  # Keep one offline
            platform.node_manager.update_status(node.node_id, NodeStatus.ONLINE)
            await platform.node_manager.heartbeat(node.node_id, {"latency_ms": random.uniform(5, 50)})
            
        online = platform.node_manager.get_online_nodes()
        print(f"  âœ“ {len(online)}/{len(created_nodes)} nodes online")
        
        # Create fleets
        print("\nðŸš€ Creating Fleets...")
        
        fleet_production = platform.fleet_manager.create(
            "production-fleet",
            selector={"environment": "production"}
        )
        
        fleet_tier1 = platform.fleet_manager.create(
            "tier1-fleet",
            selector={"tier": "tier1"}
        )
        
        print(f"  âœ“ {fleet_production.name}: {fleet_production.online_nodes}/{fleet_production.total_nodes} nodes")
        print(f"  âœ“ {fleet_tier1.name}: {fleet_tier1.online_nodes}/{fleet_tier1.total_nodes} nodes")
        
        # Create workloads
        print("\nðŸ“¦ Creating Workloads...")
        
        workloads_config = [
            ("nginx-edge", WorkloadType.CONTAINER, "nginx:latest", ResourceSpec(cpu_cores=0.5, memory_mb=256), 3),
            ("ml-inference", WorkloadType.ML_MODEL, "tensorflow-serving:latest", ResourceSpec(cpu_cores=2, memory_mb=2048, gpu_count=1), 1),
            ("data-collector", WorkloadType.FUNCTION, "data-collector:v1", ResourceSpec(cpu_cores=0.25, memory_mb=128), 5),
            ("cache-service", WorkloadType.CONTAINER, "redis:alpine", ResourceSpec(cpu_cores=0.5, memory_mb=512), 2)
        ]
        
        created_workloads = []
        for name, wtype, image, resources, replicas in workloads_config:
            workload = platform.scheduler.create(name, wtype, image, resources, replicas)
            created_workloads.append(workload)
            print(f"  âœ“ {name} ({wtype.value}): {replicas} replicas")
            
        # Schedule workloads
        print("\nâš¡ Scheduling Workloads...")
        
        for workload in created_workloads:
            result = await platform.scheduler.schedule(workload.workload_id)
            
            if "error" not in result:
                print(f"  âœ“ {workload.name}: {result['ready_replicas']} replicas on {len(result['deployed_nodes'])} nodes")
            else:
                print(f"  âœ— {workload.name}: {result['error']}")
                
        # Sync data
        print("\nðŸ”„ Synchronizing Data...")
        
        for node in online[:3]:
            sync = await platform.sync_manager.sync(
                node.node_id,
                "config",
                1024 * 100  # 100KB
            )
            print(f"  âœ“ {node.name}: {sync.data_type} synced ({sync.data_size_bytes / 1024:.1f}KB)")
            
        # Collect analytics
        print("\nðŸ“Š Collecting Edge Analytics...")
        
        for node in online:
            analytics = platform.analytics.collect(node.node_id)
            print(f"  {node.name}:")
            print(f"    RPS: {analytics.requests_per_second:.1f}")
            print(f"    Latency: {analytics.avg_latency_ms:.1f}ms")
            print(f"    CPU: {analytics.cpu_utilization * 100:.1f}%")
            
        # Aggregate analytics
        print("\nðŸ“ˆ Aggregate Analytics:")
        
        aggregate = platform.analytics.get_aggregate()
        print(f"  Average RPS: {aggregate['avg_rps']:.1f}")
        print(f"  Average Latency: {aggregate['avg_latency_ms']:.1f}ms")
        print(f"  Average Error Rate: {aggregate['avg_error_rate'] * 100:.2f}%")
        print(f"  Average CPU: {aggregate['avg_cpu'] * 100:.1f}%")
        print(f"  Average Memory: {aggregate['avg_memory'] * 100:.1f}%")
        
        # Node details
        print("\nðŸ–¥ï¸ Node Details:")
        
        for node in created_nodes:
            status_icon = "ðŸŸ¢" if node.status == NodeStatus.ONLINE else "ðŸ”´"
            sync_icon = "âœ“" if node.sync_status == SyncStatus.SYNCED else "â—‹"
            
            print(f"\n  {status_icon} {node.name} ({node.region})")
            print(f"     Location: {node.location}")
            print(f"     Latency: {node.latency_ms:.1f}ms")
            print(f"     Workloads: {node.workload_count}")
            print(f"     Resources: {node.available_resources.cpu_cores}/{node.total_resources.cpu_cores} CPU, "
                  f"{node.available_resources.memory_mb}/{node.total_resources.memory_mb}MB RAM")
            print(f"     Sync: {sync_icon} {node.sync_status.value}")
            
        # Workload status
        print("\nðŸ“¦ Workload Status:")
        
        for workload in created_workloads:
            status_icon = "âœ“" if workload.status == "running" else "â—‹"
            print(f"  {status_icon} {workload.name}: {workload.ready_replicas}/{workload.replicas} replicas")
            if workload.deployed_nodes:
                nodes_names = [platform.node_manager.nodes[nid].name for nid in workload.deployed_nodes]
                print(f"     Deployed on: {', '.join(nodes_names)}")
                
        # Check offline nodes
        print("\nâš ï¸ Checking for Offline Nodes...")
        
        offline_nodes = platform.node_manager.check_offline_nodes(timeout_seconds=300)
        if offline_nodes:
            for node in offline_nodes:
                print(f"  ðŸ”´ {node.name} is offline")
        else:
            print("  âœ“ All monitored nodes are responsive")
            
        # Statistics
        print("\nðŸ“Š Platform Statistics:")
        
        stats = platform.get_statistics()
        
        print(f"\n  Total Nodes: {stats['total_nodes']}")
        print(f"    Online: {stats['online_nodes']}")
        print(f"    Offline: {stats['offline_nodes']}")
        print(f"  Regions: {stats['regions']}")
        print(f"  Fleets: {stats['fleets']}")
        print(f"  Workloads: {stats['workloads']}")
        print(f"    Running: {stats['running_workloads']}")
        print(f"  Data Syncs: {stats['syncs']}")
        
        # Dashboard
        print("\nðŸ“‹ Edge Computing Dashboard:")
        print("  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("  â”‚               Edge Computing Overview                       â”‚")
        print("  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"  â”‚ Total Nodes:        {stats['total_nodes']:>10}                        â”‚")
        print(f"  â”‚   Online:           {stats['online_nodes']:>10}                        â”‚")
        print(f"  â”‚   Offline:          {stats['offline_nodes']:>10}                        â”‚")
        print("  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"  â”‚ Regions:            {stats['regions']:>10}                        â”‚")
        print(f"  â”‚ Fleets:             {stats['fleets']:>10}                        â”‚")
        print("  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"  â”‚ Workloads:          {stats['workloads']:>10}                        â”‚")
        print(f"  â”‚   Running:          {stats['running_workloads']:>10}                        â”‚")
        print(f"  â”‚ Data Syncs:         {stats['syncs']:>10}                        â”‚")
        print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
    asyncio.run(demo())
    
    print("\n" + "=" * 60)
    print("Edge Computing Platform initialized!")
    print("=" * 60)
