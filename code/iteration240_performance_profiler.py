#!/usr/bin/env python3
"""
Server Init - Iteration 240: Performance Profiler Platform
ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸

Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»:
- CPU Profiling - Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ CPU
- Memory Profiling - Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
- Flame Graphs - flame Ğ³Ñ€Ğ°Ñ„Ñ‹
- Call Stack Analysis - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑÑ‚ĞµĞºĞ° Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²
- Hotspot Detection - Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ³Ğ¾Ñ€ÑÑ‡Ğ¸Ñ… Ñ‚Ğ¾Ñ‡ĞµĞº
- Performance Baselines - Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸
- Continuous Profiling - Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- Profile Comparison - ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹
"""

import asyncio
import random
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Set
from enum import Enum
import uuid
import json


class ProfileType(Enum):
    """Ğ¢Ğ¸Ğ¿ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ"""
    CPU = "cpu"
    MEMORY = "memory"
    HEAP = "heap"
    GOROUTINE = "goroutine"
    BLOCK = "block"
    MUTEX = "mutex"
    ALLOCATION = "allocation"


class ProfileStatus(Enum):
    """Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ"""
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class StackFrame:
    """ĞšĞ°Ğ´Ñ€ ÑÑ‚ĞµĞºĞ°"""
    frame_id: str
    function_name: str = ""
    file_name: str = ""
    line_number: int = 0
    
    # Module/Package
    module: str = ""
    
    # Self and total time/samples
    self_samples: int = 0
    total_samples: int = 0
    
    # Percentage
    self_percent: float = 0.0
    total_percent: float = 0.0


@dataclass
class CallNode:
    """Ğ£Ğ·ĞµĞ» Ğ³Ñ€Ğ°Ñ„Ğ° Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²"""
    node_id: str
    function_name: str = ""
    
    # Metrics
    samples: int = 0
    percent: float = 0.0
    
    # Children
    children: List[str] = field(default_factory=list)  # node_ids
    
    # Parent
    parent_id: str = ""


@dataclass
class Hotspot:
    """Ğ“Ğ¾Ñ€ÑÑ‡Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ°"""
    hotspot_id: str
    function_name: str = ""
    file_name: str = ""
    
    # Metrics
    samples: int = 0
    percent: float = 0.0
    
    # Type
    hotspot_type: str = "cpu"  # cpu, memory, gc
    
    # Optimization hint
    hint: str = ""


@dataclass
class Profile:
    """ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ"""
    profile_id: str
    name: str = ""
    
    # Type
    profile_type: ProfileType = ProfileType.CPU
    
    # Target
    service: str = ""
    instance: str = ""
    
    # Duration
    duration_seconds: int = 60
    sample_rate: int = 100  # samples per second
    
    # Status
    status: ProfileStatus = ProfileStatus.RUNNING
    
    # Results
    total_samples: int = 0
    stack_frames: List[StackFrame] = field(default_factory=list)
    hotspots: List[Hotspot] = field(default_factory=list)
    
    # Times
    started_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None
    
    # Metadata
    labels: Dict[str, str] = field(default_factory=dict)


@dataclass
class MemorySnapshot:
    """Ğ¡Ğ½Ğ¸Ğ¼Ğ¾Ğº Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸"""
    snapshot_id: str
    profile_id: str = ""
    
    # Memory stats
    heap_alloc_bytes: int = 0
    heap_objects: int = 0
    stack_inuse_bytes: int = 0
    gc_cycles: int = 0
    
    # Top allocators
    top_allocators: List[Dict[str, Any]] = field(default_factory=list)
    
    # Timestamp
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class Baseline:
    """Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ»Ğ¸Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"""
    baseline_id: str
    name: str = ""
    
    # Service
    service: str = ""
    
    # Metrics
    avg_cpu_percent: float = 0.0
    avg_memory_mb: float = 0.0
    p50_latency_ms: float = 0.0
    p99_latency_ms: float = 0.0
    
    # Top functions
    top_functions: List[str] = field(default_factory=list)
    
    # Created
    created_at: datetime = field(default_factory=datetime.now)
    
    # Version
    version: str = ""


@dataclass
class Comparison:
    """Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹"""
    comparison_id: str
    
    # Profiles
    base_profile_id: str = ""
    compare_profile_id: str = ""
    
    # Differences
    cpu_diff_percent: float = 0.0
    memory_diff_percent: float = 0.0
    
    # New hotspots
    new_hotspots: List[str] = field(default_factory=list)
    
    # Resolved hotspots
    resolved_hotspots: List[str] = field(default_factory=list)
    
    # Regressions
    regressions: List[Dict[str, Any]] = field(default_factory=list)


class FlameGraphGenerator:
    """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ flame Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²"""
    
    def __init__(self):
        self.sample_functions = [
            ("main", "main.go", 1),
            ("http.Handler", "net/http/server.go", 100),
            ("json.Marshal", "encoding/json/encode.go", 200),
            ("db.Query", "database/sql/sql.go", 150),
            ("cache.Get", "cache/cache.go", 50),
            ("auth.Validate", "auth/validator.go", 75),
            ("log.Info", "log/logger.go", 30),
            ("template.Execute", "html/template/template.go", 120),
            ("compress.Gzip", "compress/gzip/gzip.go", 90),
            ("crypto.Hash", "crypto/sha256/sha256.go", 60),
        ]
        
    def generate_stack_frames(self, total_samples: int) -> List[StackFrame]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑÑ‚ĞµĞº Ñ„Ñ€ĞµĞ¹Ğ¼Ğ¾Ğ²"""
        frames = []
        remaining_samples = total_samples
        
        for func, file, base_samples in self.sample_functions:
            if remaining_samples <= 0:
                break
                
            samples = min(
                random.randint(base_samples, base_samples * 3),
                remaining_samples
            )
            
            frame = StackFrame(
                frame_id=f"frame_{uuid.uuid4().hex[:8]}",
                function_name=func,
                file_name=file,
                line_number=random.randint(10, 500),
                module=file.split("/")[0] if "/" in file else "main",
                self_samples=samples,
                total_samples=samples + random.randint(0, samples // 2),
                self_percent=(samples / total_samples * 100) if total_samples > 0 else 0,
                total_percent=((samples + random.randint(0, samples // 2)) / total_samples * 100) if total_samples > 0 else 0
            )
            
            frames.append(frame)
            remaining_samples -= samples
            
        return sorted(frames, key=lambda f: -f.self_samples)
        
    def generate_hotspots(self, frames: List[StackFrame]) -> List[Hotspot]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ³Ğ¾Ñ€ÑÑ‡Ğ¸Ñ… Ñ‚Ğ¾Ñ‡ĞµĞº"""
        hotspots = []
        
        # Top 5 frames as hotspots
        for frame in frames[:5]:
            hints = [
                "Consider caching this result",
                "Optimize algorithm complexity",
                "Use connection pooling",
                "Reduce allocations",
                "Consider async processing"
            ]
            
            hotspot = Hotspot(
                hotspot_id=f"hot_{uuid.uuid4().hex[:8]}",
                function_name=frame.function_name,
                file_name=frame.file_name,
                samples=frame.self_samples,
                percent=frame.self_percent,
                hint=random.choice(hints)
            )
            
            hotspots.append(hotspot)
            
        return hotspots


class PerformanceProfilerPlatform:
    """ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"""
    
    def __init__(self):
        self.profiles: Dict[str, Profile] = {}
        self.snapshots: List[MemorySnapshot] = []
        self.baselines: Dict[str, Baseline] = {}
        self.comparisons: List[Comparison] = []
        self.flame_generator = FlameGraphGenerator()
        
    def start_profile(self, name: str, service: str,
                     profile_type: ProfileType = ProfileType.CPU,
                     duration_seconds: int = 60,
                     sample_rate: int = 100) -> Profile:
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        profile = Profile(
            profile_id=f"prof_{uuid.uuid4().hex[:8]}",
            name=name,
            profile_type=profile_type,
            service=service,
            instance=f"{service}-{random.randint(1, 5)}",
            duration_seconds=duration_seconds,
            sample_rate=sample_rate
        )
        
        self.profiles[profile.profile_id] = profile
        return profile
        
    def complete_profile(self, profile_id: str) -> Optional[Profile]:
        """Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        profile = self.profiles.get(profile_id)
        if not profile:
            return None
            
        # Generate samples
        profile.total_samples = profile.duration_seconds * profile.sample_rate
        
        # Generate stack frames
        profile.stack_frames = self.flame_generator.generate_stack_frames(
            profile.total_samples
        )
        
        # Generate hotspots
        profile.hotspots = self.flame_generator.generate_hotspots(
            profile.stack_frames
        )
        
        profile.status = ProfileStatus.COMPLETED
        profile.completed_at = datetime.now()
        
        return profile
        
    def take_memory_snapshot(self, profile_id: str) -> MemorySnapshot:
        """Ğ¡Ğ½Ğ¸Ğ¼Ğ¾Ğº Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸"""
        snapshot = MemorySnapshot(
            snapshot_id=f"snap_{uuid.uuid4().hex[:8]}",
            profile_id=profile_id,
            heap_alloc_bytes=random.randint(100000000, 500000000),
            heap_objects=random.randint(100000, 500000),
            stack_inuse_bytes=random.randint(1000000, 10000000),
            gc_cycles=random.randint(10, 100)
        )
        
        # Top allocators
        allocators = [
            ("[]byte", random.randint(10000000, 50000000)),
            ("string", random.randint(5000000, 20000000)),
            ("map[string]interface{}", random.randint(1000000, 10000000)),
            ("*http.Request", random.randint(500000, 5000000)),
            ("json.RawMessage", random.randint(100000, 1000000)),
        ]
        
        snapshot.top_allocators = [
            {"type": t, "bytes": b, "percent": b / snapshot.heap_alloc_bytes * 100}
            for t, b in allocators
        ]
        
        self.snapshots.append(snapshot)
        return snapshot
        
    def create_baseline(self, name: str, service: str,
                       profile_id: str = None) -> Baseline:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¹ Ğ»Ğ¸Ğ½Ğ¸Ğ¸"""
        baseline = Baseline(
            baseline_id=f"base_{uuid.uuid4().hex[:8]}",
            name=name,
            service=service,
            avg_cpu_percent=random.uniform(20, 60),
            avg_memory_mb=random.uniform(256, 1024),
            p50_latency_ms=random.uniform(5, 50),
            p99_latency_ms=random.uniform(50, 500)
        )
        
        if profile_id:
            profile = self.profiles.get(profile_id)
            if profile:
                baseline.top_functions = [
                    f.function_name for f in profile.stack_frames[:5]
                ]
                
        self.baselines[baseline.baseline_id] = baseline
        return baseline
        
    def compare_profiles(self, base_id: str, compare_id: str) -> Optional[Comparison]:
        """Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹"""
        base = self.profiles.get(base_id)
        compare = self.profiles.get(compare_id)
        
        if not base or not compare:
            return None
            
        comparison = Comparison(
            comparison_id=f"cmp_{uuid.uuid4().hex[:8]}",
            base_profile_id=base_id,
            compare_profile_id=compare_id,
            cpu_diff_percent=random.uniform(-20, 30),
            memory_diff_percent=random.uniform(-10, 25)
        )
        
        # Find new hotspots
        base_functions = {f.function_name for f in base.stack_frames[:10]}
        compare_functions = {f.function_name for f in compare.stack_frames[:10]}
        
        comparison.new_hotspots = list(compare_functions - base_functions)
        comparison.resolved_hotspots = list(base_functions - compare_functions)
        
        # Check for regressions
        if comparison.cpu_diff_percent > 10:
            comparison.regressions.append({
                "type": "cpu",
                "change": f"+{comparison.cpu_diff_percent:.1f}%",
                "severity": "high" if comparison.cpu_diff_percent > 20 else "medium"
            })
            
        if comparison.memory_diff_percent > 15:
            comparison.regressions.append({
                "type": "memory",
                "change": f"+{comparison.memory_diff_percent:.1f}%",
                "severity": "high" if comparison.memory_diff_percent > 25 else "medium"
            })
            
        self.comparisons.append(comparison)
        return comparison
        
    def get_statistics(self) -> Dict[str, Any]:
        """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"""
        profiles = list(self.profiles.values())
        completed = [p for p in profiles if p.status == ProfileStatus.COMPLETED]
        
        # By type
        by_type = {}
        for p in profiles:
            t = p.profile_type.value
            by_type[t] = by_type.get(t, 0) + 1
            
        # Total samples
        total_samples = sum(p.total_samples for p in completed)
        
        # Total hotspots
        total_hotspots = sum(len(p.hotspots) for p in completed)
        
        return {
            "total_profiles": len(profiles),
            "completed_profiles": len(completed),
            "total_samples": total_samples,
            "total_hotspots": total_hotspots,
            "memory_snapshots": len(self.snapshots),
            "baselines": len(self.baselines),
            "comparisons": len(self.comparisons),
            "profiles_by_type": by_type
        }


# Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ
async def main():
    print("=" * 60)
    print("Server Init - Iteration 240: Performance Profiler Platform")
    print("=" * 60)
    
    platform = PerformanceProfilerPlatform()
    print("âœ“ Performance Profiler Platform created")
    
    # Start profiles
    print("\nğŸ“Š Starting Performance Profiles...")
    
    profiles_config = [
        ("API Service CPU", "api-service", ProfileType.CPU, 60),
        ("API Service Memory", "api-service", ProfileType.MEMORY, 30),
        ("Worker CPU", "worker-service", ProfileType.CPU, 60),
        ("Gateway Heap", "api-gateway", ProfileType.HEAP, 45),
        ("Auth Service", "auth-service", ProfileType.CPU, 60),
    ]
    
    profiles = []
    for name, service, ptype, duration in profiles_config:
        profile = platform.start_profile(name, service, ptype, duration)
        profiles.append(profile)
        
        type_icons = {
            ProfileType.CPU: "ğŸ”¥",
            ProfileType.MEMORY: "ğŸ’¾",
            ProfileType.HEAP: "ğŸ“Š",
            ProfileType.GOROUTINE: "ğŸ”„",
            ProfileType.ALLOCATION: "ğŸ“¦"
        }
        icon = type_icons.get(ptype, "ğŸ“Š")
        print(f"  {icon} {name} ({service}, {duration}s)")
        
    # Complete profiles
    print("\nâ±ï¸ Completing Profiles...")
    
    for profile in profiles:
        completed = platform.complete_profile(profile.profile_id)
        if completed:
            print(f"  âœ“ {completed.name}: {completed.total_samples} samples")
            
    # Take memory snapshots
    print("\nğŸ“¸ Taking Memory Snapshots...")
    
    for profile in profiles[:2]:
        snapshot = platform.take_memory_snapshot(profile.profile_id)
        heap_mb = snapshot.heap_alloc_bytes / (1024**2)
        print(f"  ğŸ“¸ {profile.name}: {heap_mb:.1f} MB heap, {snapshot.heap_objects} objects")
        
    # Create baselines
    print("\nğŸ“ Creating Performance Baselines...")
    
    baselines = [
        platform.create_baseline("API Service v2.0", "api-service", profiles[0].profile_id),
        platform.create_baseline("Worker Service v1.5", "worker-service", profiles[2].profile_id),
    ]
    
    for baseline in baselines:
        print(f"  ğŸ“ {baseline.name}: CPU={baseline.avg_cpu_percent:.1f}%, Mem={baseline.avg_memory_mb:.0f}MB")
        
    # Compare profiles
    print("\nğŸ”„ Comparing Profiles...")
    
    comparison = platform.compare_profiles(profiles[0].profile_id, profiles[2].profile_id)
    if comparison:
        cpu_symbol = "ğŸ“ˆ" if comparison.cpu_diff_percent > 0 else "ğŸ“‰"
        mem_symbol = "ğŸ“ˆ" if comparison.memory_diff_percent > 0 else "ğŸ“‰"
        print(f"  {cpu_symbol} CPU: {comparison.cpu_diff_percent:+.1f}%")
        print(f"  {mem_symbol} Memory: {comparison.memory_diff_percent:+.1f}%")
        
        if comparison.regressions:
            print("  âš ï¸ Regressions detected!")
            
    # Display profiles
    print("\nğŸ“Š Performance Profiles:")
    
    print("\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("  â”‚ Profile                        â”‚ Type         â”‚ Samples  â”‚ Status   â”‚")
    print("  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    for profile in platform.profiles.values():
        name = profile.name[:30].ljust(30)
        ptype = profile.profile_type.value[:12].ljust(12)
        samples = str(profile.total_samples)[:8].ljust(8)
        
        status_icons = {
            ProfileStatus.COMPLETED: "ğŸŸ¢",
            ProfileStatus.RUNNING: "ğŸ”µ",
            ProfileStatus.FAILED: "ğŸ”´",
            ProfileStatus.CANCELLED: "âš«"
        }
        status = status_icons.get(profile.status, "âšª")[:8].ljust(8)
        
        print(f"  â”‚ {name} â”‚ {ptype} â”‚ {samples} â”‚ {status} â”‚")
        
    print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    # Display hotspots
    print("\nğŸ”¥ Top Hotspots:")
    
    sample_profile = profiles[0]
    
    print("\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("  â”‚ Function                       â”‚ Samples  â”‚ Percent  â”‚")
    print("  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    for hotspot in sample_profile.hotspots[:5]:
        func = hotspot.function_name[:30].ljust(30)
        samples = str(hotspot.samples)[:8].ljust(8)
        pct = f"{hotspot.percent:.1f}%"[:8].ljust(8)
        
        print(f"  â”‚ {func} â”‚ {samples} â”‚ {pct} â”‚")
        
    print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    # Flame graph visualization (simplified)
    print("\nğŸ”¥ Flame Graph (simplified):")
    
    print("\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    for frame in sample_profile.stack_frames[:5]:
        bar_len = int(frame.self_percent / 2)
        bar = "â–ˆ" * bar_len
        
        func = frame.function_name[:15].ljust(15)
        print(f"  â”‚ {func} {bar}")
        
    print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    # Memory analysis
    print("\nğŸ’¾ Memory Analysis:")
    
    for snapshot in platform.snapshots[:2]:
        print(f"\n  Snapshot: {snapshot.snapshot_id}")
        print(f"  Heap Alloc: {snapshot.heap_alloc_bytes / (1024**2):.1f} MB")
        print(f"  Heap Objects: {snapshot.heap_objects:,}")
        print(f"  GC Cycles: {snapshot.gc_cycles}")
        
        print("  Top Allocators:")
        for alloc in snapshot.top_allocators[:3]:
            mb = alloc["bytes"] / (1024**2)
            print(f"    {alloc['type']}: {mb:.1f} MB ({alloc['percent']:.1f}%)")
            
    # Optimization hints
    print("\nğŸ’¡ Optimization Hints:")
    
    for hotspot in sample_profile.hotspots[:3]:
        print(f"  âš¡ {hotspot.function_name}")
        print(f"     {hotspot.hint}")
        
    # Profile comparison
    if comparison:
        print("\nğŸ“ˆ Profile Comparison:")
        
        print(f"\n  Base: {profiles[0].name}")
        print(f"  Compare: {profiles[2].name}")
        print(f"\n  CPU Difference: {comparison.cpu_diff_percent:+.1f}%")
        print(f"  Memory Difference: {comparison.memory_diff_percent:+.1f}%")
        
        if comparison.new_hotspots:
            print(f"\n  New Hotspots: {', '.join(comparison.new_hotspots[:3])}")
            
        if comparison.resolved_hotspots:
            print(f"  Resolved Hotspots: {', '.join(comparison.resolved_hotspots[:3])}")
            
    # Baselines
    print("\nğŸ“ Performance Baselines:")
    
    for baseline in platform.baselines.values():
        print(f"\n  {baseline.name}:")
        print(f"    CPU: {baseline.avg_cpu_percent:.1f}%")
        print(f"    Memory: {baseline.avg_memory_mb:.0f} MB")
        print(f"    P50 Latency: {baseline.p50_latency_ms:.1f} ms")
        print(f"    P99 Latency: {baseline.p99_latency_ms:.1f} ms")
        
    # Statistics
    print("\nğŸ“Š Platform Statistics:")
    
    stats = platform.get_statistics()
    
    print(f"\n  Total Profiles: {stats['total_profiles']}")
    print(f"  Completed: {stats['completed_profiles']}")
    print(f"  Total Samples: {stats['total_samples']:,}")
    print(f"  Total Hotspots: {stats['total_hotspots']}")
    print(f"  Memory Snapshots: {stats['memory_snapshots']}")
    print(f"  Baselines: {stats['baselines']}")
    
    # Profile type distribution
    print("\n  By Profile Type:")
    type_icons = {"cpu": "ğŸ”¥", "memory": "ğŸ’¾", "heap": "ğŸ“Š", "goroutine": "ğŸ”„", "allocation": "ğŸ“¦"}
    for ptype, count in stats['profiles_by_type'].items():
        icon = type_icons.get(ptype, "ğŸ“Š")
        bar = "â–ˆ" * (count * 2) + "â–‘" * (10 - count * 2)
        print(f"    {icon} {ptype:12s} [{bar}] {count}")
        
    # Dashboard
    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚                  Performance Profiler Dashboard                     â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚ Total Profiles:                {stats['total_profiles']:>12}                        â”‚")
    print(f"â”‚ Total Samples:                {stats['total_samples']:>13,}                       â”‚")
    print(f"â”‚ Hotspots Detected:             {stats['total_hotspots']:>12}                        â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚ Memory Snapshots:              {stats['memory_snapshots']:>12}                        â”‚")
    print(f"â”‚ Performance Baselines:         {stats['baselines']:>12}                        â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    print("\n" + "=" * 60)
    print("Performance Profiler Platform initialized!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
