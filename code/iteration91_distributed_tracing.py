#!/usr/bin/env python3
"""
Server Init - Iteration 91: Distributed Tracing Platform
ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸

Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»:
- Span Management - ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ°Ğ½Ğ°Ğ¼Ğ¸
- Context Propagation - Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
- Trace Aggregation - Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ñ Ñ‚Ñ€ĞµĞ¹ÑĞ¾Ğ²
- Service Map - ĞºĞ°Ñ€Ñ‚Ğ° ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
- Latency Analysis - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞµĞº
- Error Tracking - Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
- Performance Insights - Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
- Root Cause Analysis - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½
"""

import json
import asyncio
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Set, Callable, Tuple
from enum import Enum
from collections import defaultdict
import uuid
import random


class SpanKind(Enum):
    """Ğ¢Ğ¸Ğ¿ ÑĞ¿Ğ°Ğ½Ğ°"""
    INTERNAL = "internal"
    SERVER = "server"
    CLIENT = "client"
    PRODUCER = "producer"
    CONSUMER = "consumer"


class SpanStatus(Enum):
    """Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ ÑĞ¿Ğ°Ğ½Ğ°"""
    UNSET = "unset"
    OK = "ok"
    ERROR = "error"


class AlertSeverity(Enum):
    """Ğ¡ĞµÑ€ÑŒÑ‘Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ Ğ°Ğ»ĞµÑ€Ñ‚Ğ°"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class SpanContext:
    """ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ÑĞ¿Ğ°Ğ½Ğ°"""
    trace_id: str
    span_id: str
    parent_span_id: Optional[str] = None
    trace_flags: int = 0
    baggage: Dict[str, str] = field(default_factory=dict)


@dataclass
class SpanEvent:
    """Ğ¡Ğ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ ÑĞ¿Ğ°Ğ½Ğ°"""
    name: str
    timestamp: datetime = field(default_factory=datetime.now)
    attributes: Dict[str, Any] = field(default_factory=dict)


@dataclass
class SpanLink:
    """Ğ¡Ğ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¿Ğ°Ğ½Ğ°Ğ¼Ğ¸"""
    context: SpanContext
    attributes: Dict[str, Any] = field(default_factory=dict)


@dataclass
class Span:
    """Ğ¡Ğ¿Ğ°Ğ½ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸"""
    context: SpanContext
    name: str
    kind: SpanKind = SpanKind.INTERNAL
    status: SpanStatus = SpanStatus.UNSET
    
    # Ğ’Ñ€ĞµĞ¼Ñ
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    
    # ĞÑ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ñ‹
    attributes: Dict[str, Any] = field(default_factory=dict)
    
    # Ğ¡Ğ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ
    events: List[SpanEvent] = field(default_factory=list)
    
    # Ğ¡Ğ²ÑĞ·Ğ¸
    links: List[SpanLink] = field(default_factory=list)
    
    # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ
    service_name: str = ""
    service_version: str = ""
    
    # Ğ ĞµÑÑƒÑ€Ñ
    resource: Dict[str, str] = field(default_factory=dict)
    
    # ĞÑˆĞ¸Ğ±ĞºĞ°
    error_message: str = ""
    exception_type: str = ""
    stack_trace: str = ""
    
    @property
    def duration_ms(self) -> float:
        """Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ¼Ñ"""
        if self.end_time:
            return (self.end_time - self.start_time).total_seconds() * 1000
        return 0


@dataclass
class Trace:
    """Ğ¢Ñ€ĞµĞ¹Ñ (ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ ÑĞ¿Ğ°Ğ½Ğ¾Ğ²)"""
    trace_id: str
    spans: List[Span] = field(default_factory=list)
    
    # ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    root_span: Optional[Span] = None
    service_count: int = 0
    span_count: int = 0
    
    # Ğ’Ñ€ĞµĞ¼Ñ
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    
    @property
    def duration_ms(self) -> float:
        """ĞĞ±Ñ‰Ğ°Ñ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds() * 1000
        return 0
    
    @property
    def has_errors(self) -> bool:
        """Ğ•ÑÑ‚ÑŒ Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸"""
        return any(span.status == SpanStatus.ERROR for span in self.spans)


@dataclass
class ServiceInfo:
    """Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑĞµÑ€Ğ²Ğ¸ÑĞµ"""
    service_name: str
    version: str = ""
    
    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    total_spans: int = 0
    error_count: int = 0
    
    # Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸
    avg_latency_ms: float = 0
    p50_latency_ms: float = 0
    p95_latency_ms: float = 0
    p99_latency_ms: float = 0
    
    # Ğ¡Ğ²ÑĞ·Ğ¸
    calls_to: Dict[str, int] = field(default_factory=dict)  # service -> count
    called_by: Dict[str, int] = field(default_factory=dict)
    
    # ĞĞ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
    operations: Dict[str, int] = field(default_factory=dict)


@dataclass
class ServiceEdge:
    """Ğ¡Ğ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼Ğ¸"""
    source: str
    target: str
    
    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    call_count: int = 0
    error_count: int = 0
    avg_latency_ms: float = 0
    
    # ĞŸÑ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»
    protocol: str = "http"


@dataclass
class LatencyHistogram:
    """Ğ“Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞµĞº"""
    buckets: Dict[str, int] = field(default_factory=dict)
    total_count: int = 0
    sum_ms: float = 0
    
    @property
    def avg_ms(self) -> float:
        return self.sum_ms / self.total_count if self.total_count > 0 else 0


@dataclass
class TracingAlert:
    """ĞĞ»ĞµÑ€Ñ‚ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸"""
    alert_id: str
    severity: AlertSeverity = AlertSeverity.WARNING
    title: str = ""
    description: str = ""
    
    # Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞ¹Ñ
    trace_id: str = ""
    span_id: str = ""
    service: str = ""
    
    # Ğ’Ñ€ĞµĞ¼Ñ
    timestamp: datetime = field(default_factory=datetime.now)
    
    # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ
    acknowledged: bool = False


class SpanProcessor:
    """ĞŸÑ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€ ÑĞ¿Ğ°Ğ½Ğ¾Ğ²"""
    
    def __init__(self):
        self.processors: List[Callable] = []
        
    def add_processor(self, processor: Callable):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°"""
        self.processors.append(processor)
        
    async def process(self, span: Span) -> Span:
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¿Ğ°Ğ½Ğ°"""
        for processor in self.processors:
            if asyncio.iscoroutinefunction(processor):
                span = await processor(span)
            else:
                span = processor(span)
        return span


class ContextPropagator:
    """Ğ Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°"""
    
    TRACE_HEADER = "traceparent"
    BAGGAGE_HEADER = "baggage"
    
    def inject(self, context: SpanContext) -> Dict[str, str]:
        """Ğ’Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸"""
        headers = {}
        
        # W3C Trace Context format
        trace_parent = f"00-{context.trace_id}-{context.span_id}-{context.trace_flags:02x}"
        headers[self.TRACE_HEADER] = trace_parent
        
        # Baggage
        if context.baggage:
            baggage = ",".join(f"{k}={v}" for k, v in context.baggage.items())
            headers[self.BAGGAGE_HEADER] = baggage
            
        return headers
        
    def extract(self, headers: Dict[str, str]) -> Optional[SpanContext]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ²"""
        trace_parent = headers.get(self.TRACE_HEADER)
        if not trace_parent:
            return None
            
        try:
            parts = trace_parent.split("-")
            if len(parts) < 4:
                return None
                
            context = SpanContext(
                trace_id=parts[1],
                span_id=parts[2],
                trace_flags=int(parts[3], 16)
            )
            
            # Baggage
            baggage = headers.get(self.BAGGAGE_HEADER, "")
            if baggage:
                for item in baggage.split(","):
                    if "=" in item:
                        k, v = item.split("=", 1)
                        context.baggage[k.strip()] = v.strip()
                        
            return context
            
        except Exception:
            return None


class Tracer:
    """Ğ¢Ñ€ĞµĞ¹ÑĞµÑ€"""
    
    def __init__(self, service_name: str, version: str = "1.0.0"):
        self.service_name = service_name
        self.version = version
        self.span_processor = SpanProcessor()
        self.propagator = ContextPropagator()
        
        # Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğµ ÑĞ¿Ğ°Ğ½Ñ‹
        self.active_spans: Dict[str, Span] = {}
        
        # Callback Ğ´Ğ»Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
        self.on_span_end: Optional[Callable] = None
        
    def start_span(self, name: str, parent: Optional[SpanContext] = None,
                    kind: SpanKind = SpanKind.INTERNAL,
                    attributes: Dict[str, Any] = None) -> Span:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¿Ğ°Ğ½Ğ°"""
        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ IDs
        trace_id = parent.trace_id if parent else uuid.uuid4().hex
        span_id = uuid.uuid4().hex[:16]
        parent_span_id = parent.span_id if parent else None
        
        context = SpanContext(
            trace_id=trace_id,
            span_id=span_id,
            parent_span_id=parent_span_id,
            baggage=parent.baggage.copy() if parent else {}
        )
        
        span = Span(
            context=context,
            name=name,
            kind=kind,
            service_name=self.service_name,
            service_version=self.version,
            attributes=attributes or {}
        )
        
        self.active_spans[span_id] = span
        return span
        
    async def end_span(self, span: Span, status: SpanStatus = SpanStatus.OK,
                        error: Exception = None):
        """Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ°Ğ½Ğ°"""
        span.end_time = datetime.now()
        span.status = status
        
        if error:
            span.status = SpanStatus.ERROR
            span.error_message = str(error)
            span.exception_type = type(error).__name__
            
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
        span = await self.span_processor.process(span)
        
        # Callback
        if self.on_span_end:
            if asyncio.iscoroutinefunction(self.on_span_end):
                await self.on_span_end(span)
            else:
                self.on_span_end(span)
                
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¸Ğ· Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…
        self.active_spans.pop(span.context.span_id, None)
        
        return span


class TraceAggregator:
    """ĞĞ³Ñ€ĞµĞ³Ğ°Ñ‚Ğ¾Ñ€ Ñ‚Ñ€ĞµĞ¹ÑĞ¾Ğ²"""
    
    def __init__(self):
        self.traces: Dict[str, Trace] = {}
        self.spans_buffer: Dict[str, List[Span]] = defaultdict(list)
        
    def add_span(self, span: Span):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ°Ğ½Ğ°"""
        trace_id = span.context.trace_id
        self.spans_buffer[trace_id].append(span)
        
    def build_trace(self, trace_id: str) -> Optional[Trace]:
        """ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€ĞµĞ¹ÑĞ°"""
        spans = self.spans_buffer.get(trace_id, [])
        if not spans:
            return None
            
        trace = Trace(trace_id=trace_id, spans=spans)
        
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ root span
        for span in spans:
            if span.context.parent_span_id is None:
                trace.root_span = span
                break
                
        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
        trace.span_count = len(spans)
        trace.service_count = len(set(s.service_name for s in spans))
        
        # Ğ’Ñ€ĞµĞ¼Ñ
        if spans:
            trace.start_time = min(s.start_time for s in spans)
            end_times = [s.end_time for s in spans if s.end_time]
            if end_times:
                trace.end_time = max(end_times)
                
        self.traces[trace_id] = trace
        return trace
        
    def get_trace(self, trace_id: str) -> Optional[Trace]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€ĞµĞ¹ÑĞ°"""
        if trace_id not in self.traces:
            return self.build_trace(trace_id)
        return self.traces.get(trace_id)


class ServiceMap:
    """ĞšĞ°Ñ€Ñ‚Ğ° ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²"""
    
    def __init__(self):
        self.services: Dict[str, ServiceInfo] = {}
        self.edges: Dict[str, ServiceEdge] = {}  # "source->target" -> edge
        
    def update_from_span(self, span: Span):
        """ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ĞºĞ°Ñ€Ñ‚Ñ‹ Ğ¸Ğ· ÑĞ¿Ğ°Ğ½Ğ°"""
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑĞµÑ€Ğ²Ğ¸ÑĞµ
        if span.service_name not in self.services:
            self.services[span.service_name] = ServiceInfo(
                service_name=span.service_name,
                version=span.service_version
            )
            
        service = self.services[span.service_name]
        service.total_spans += 1
        
        if span.status == SpanStatus.ERROR:
            service.error_count += 1
            
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
        service.operations[span.name] = service.operations.get(span.name, 0) + 1
        
    def add_call(self, source: str, target: str, latency_ms: float, error: bool = False):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ°"""
        edge_key = f"{source}->{target}"
        
        if edge_key not in self.edges:
            self.edges[edge_key] = ServiceEdge(source=source, target=target)
            
        edge = self.edges[edge_key]
        edge.call_count += 1
        
        if error:
            edge.error_count += 1
            
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ avg latency (Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğµ ÑĞºĞ¾Ğ»ÑŒĞ·ÑÑ‰ĞµĞµ ÑÑ€ĞµĞ´Ğ½ĞµĞµ)
        edge.avg_latency_ms = (edge.avg_latency_ms * (edge.call_count - 1) + latency_ms) / edge.call_count
        
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑĞ²ÑĞ·Ğ¸ Ğ² ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ñ…
        if source in self.services:
            self.services[source].calls_to[target] = self.services[source].calls_to.get(target, 0) + 1
        if target in self.services:
            self.services[target].called_by[source] = self.services[target].called_by.get(source, 0) + 1


class LatencyAnalyzer:
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞµĞº"""
    
    def __init__(self):
        self.histograms: Dict[str, LatencyHistogram] = {}
        self.latencies: Dict[str, List[float]] = defaultdict(list)
        
    def record(self, service: str, operation: str, latency_ms: float):
        """Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸"""
        key = f"{service}:{operation}"
        self.latencies[key].append(latency_ms)
        
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ³Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ
        if key not in self.histograms:
            self.histograms[key] = LatencyHistogram()
            
        histogram = self.histograms[key]
        histogram.total_count += 1
        histogram.sum_ms += latency_ms
        
        # Bucket
        bucket = self._get_bucket(latency_ms)
        histogram.buckets[bucket] = histogram.buckets.get(bucket, 0) + 1
        
    def _get_bucket(self, latency_ms: float) -> str:
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ bucket Ğ´Ğ»Ñ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸"""
        if latency_ms < 10:
            return "0-10ms"
        elif latency_ms < 50:
            return "10-50ms"
        elif latency_ms < 100:
            return "50-100ms"
        elif latency_ms < 500:
            return "100-500ms"
        elif latency_ms < 1000:
            return "500ms-1s"
        else:
            return ">1s"
            
    def get_percentiles(self, service: str, operation: str) -> Dict[str, float]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€Ñ†ĞµĞ½Ñ‚Ğ¸Ğ»ĞµĞ¹"""
        key = f"{service}:{operation}"
        values = sorted(self.latencies.get(key, []))
        
        if not values:
            return {}
            
        def percentile(p: float) -> float:
            idx = int(len(values) * p / 100)
            return values[min(idx, len(values) - 1)]
            
        return {
            "p50": percentile(50),
            "p75": percentile(75),
            "p90": percentile(90),
            "p95": percentile(95),
            "p99": percentile(99)
        }


class RootCauseAnalyzer:
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ ĞºĞ¾Ñ€Ğ½ĞµĞ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½"""
    
    def analyze_error_trace(self, trace: Trace) -> Dict[str, Any]:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚Ñ€ĞµĞ¹ÑĞ° Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¾Ğ¹"""
        analysis = {
            "root_cause_span": None,
            "error_path": [],
            "affected_services": set(),
            "suggestions": []
        }
        
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ÑĞ¿Ğ°Ğ½ Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¾Ğ¹
        error_spans = [s for s in trace.spans if s.status == SpanStatus.ERROR]
        
        if not error_spans:
            return analysis
            
        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
        error_spans.sort(key=lambda s: s.start_time)
        root_cause = error_spans[0]
        analysis["root_cause_span"] = root_cause
        
        # ĞŸÑƒÑ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
        analysis["error_path"] = self._build_error_path(trace, root_cause)
        
        # Ğ—Ğ°Ñ‚Ñ€Ğ¾Ğ½ÑƒÑ‚Ñ‹Ğµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹
        analysis["affected_services"] = set(s.service_name for s in error_spans)
        
        # ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
        analysis["suggestions"] = self._generate_suggestions(root_cause)
        
        return analysis
        
    def _build_error_path(self, trace: Trace, root_span: Span) -> List[str]:
        """ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¿ÑƒÑ‚Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸"""
        path = [f"{root_span.service_name}:{root_span.name}"]
        
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğµ ÑĞ¿Ğ°Ğ½Ñ‹
        span_map = {s.context.span_id: s for s in trace.spans}
        current = root_span
        
        while current.context.parent_span_id:
            parent = span_map.get(current.context.parent_span_id)
            if parent:
                path.insert(0, f"{parent.service_name}:{parent.name}")
                current = parent
            else:
                break
                
        return path
        
    def _generate_suggestions(self, span: Span) -> List[str]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹"""
        suggestions = []
        
        if "timeout" in span.error_message.lower():
            suggestions.append("Consider increasing timeout settings")
            suggestions.append("Check network latency between services")
            
        if "connection" in span.error_message.lower():
            suggestions.append("Verify service connectivity")
            suggestions.append("Check connection pool settings")
            
        if span.duration_ms > 1000:
            suggestions.append("Operation took too long, consider optimization")
            
        if not suggestions:
            suggestions.append("Review logs for more details")
            suggestions.append("Check service health status")
            
        return suggestions


class AlertManager:
    """ĞœĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²"""
    
    def __init__(self):
        self.alerts: List[TracingAlert] = []
        self.rules: List[Dict[str, Any]] = []
        
    def add_rule(self, name: str, condition: Callable, severity: AlertSeverity):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°"""
        self.rules.append({
            "name": name,
            "condition": condition,
            "severity": severity
        })
        
    def check_span(self, span: Span) -> Optional[TracingAlert]:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¿Ğ°Ğ½Ğ° Ğ½Ğ° Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹"""
        for rule in self.rules:
            if rule["condition"](span):
                alert = TracingAlert(
                    alert_id=f"alert_{uuid.uuid4().hex[:8]}",
                    severity=rule["severity"],
                    title=rule["name"],
                    description=f"Alert triggered for span {span.name}",
                    trace_id=span.context.trace_id,
                    span_id=span.context.span_id,
                    service=span.service_name
                )
                self.alerts.append(alert)
                return alert
                
        return None


class DistributedTracingPlatform:
    """ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸"""
    
    def __init__(self):
        self.tracers: Dict[str, Tracer] = {}
        self.aggregator = TraceAggregator()
        self.service_map = ServiceMap()
        self.latency_analyzer = LatencyAnalyzer()
        self.root_cause_analyzer = RootCauseAnalyzer()
        self.alert_manager = AlertManager()
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ» Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²
        self._setup_default_alerts()
        
    def _setup_default_alerts(self):
        """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ"""
        # Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ°
        self.alert_manager.add_rule(
            "High Latency",
            lambda span: span.duration_ms > 5000,
            AlertSeverity.WARNING
        )
        
        # ĞÑˆĞ¸Ğ±ĞºĞ¸
        self.alert_manager.add_rule(
            "Span Error",
            lambda span: span.status == SpanStatus.ERROR,
            AlertSeverity.ERROR
        )
        
    def create_tracer(self, service_name: str, version: str = "1.0.0") -> Tracer:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ñ€ĞµĞ¹ÑĞµÑ€Ğ° Ğ´Ğ»Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ°"""
        tracer = Tracer(service_name, version)
        
        # Callback Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½Ğ½Ñ‹Ñ… ÑĞ¿Ğ°Ğ½Ğ¾Ğ²
        async def on_span_end(span: Span):
            self.aggregator.add_span(span)
            self.service_map.update_from_span(span)
            
            if span.duration_ms > 0:
                self.latency_analyzer.record(
                    span.service_name,
                    span.name,
                    span.duration_ms
                )
                
            self.alert_manager.check_span(span)
            
        tracer.on_span_end = on_span_end
        self.tracers[service_name] = tracer
        return tracer
        
    async def simulate_distributed_call(self, services: List[str],
                                          operations: List[str]) -> str:
        """Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ°"""
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ‚Ñ€ĞµĞ¹ÑĞµÑ€Ñ‹ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
        for service in services:
            if service not in self.tracers:
                self.create_tracer(service)
                
        trace_id = None
        parent_context = None
        
        for i, (service, operation) in enumerate(zip(services, operations)):
            tracer = self.tracers[service]
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑĞ¿Ğ°Ğ½
            span = tracer.start_span(
                operation,
                parent=parent_context,
                kind=SpanKind.SERVER if i > 0 else SpanKind.INTERNAL,
                attributes={
                    "http.method": "GET",
                    "http.url": f"http://{service}/{operation}"
                }
            )
            
            if trace_id is None:
                trace_id = span.context.trace_id
                
            # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
            await asyncio.sleep(random.uniform(0.01, 0.1))
            
            # Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°
            error = None
            if random.random() < 0.1:
                error = Exception(f"Simulated error in {service}:{operation}")
                
            # Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞ°ĞµĞ¼ ÑĞ¿Ğ°Ğ½
            await tracer.end_span(
                span,
                status=SpanStatus.ERROR if error else SpanStatus.OK,
                error=error
            )
            
            # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼Ğ¸
            if parent_context:
                prev_service = services[i - 1]
                self.service_map.add_call(
                    prev_service,
                    service,
                    span.duration_ms,
                    error is not None
                )
                
            parent_context = span.context
            
        return trace_id
        
    def get_statistics(self) -> Dict[str, Any]:
        """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"""
        total_spans = sum(len(spans) for spans in self.aggregator.spans_buffer.values())
        error_spans = sum(
            1 for spans in self.aggregator.spans_buffer.values()
            for span in spans if span.status == SpanStatus.ERROR
        )
        
        return {
            "total_traces": len(self.aggregator.traces),
            "total_spans": total_spans,
            "services": len(self.service_map.services),
            "edges": len(self.service_map.edges),
            "error_spans": error_spans,
            "error_rate": (error_spans / total_spans * 100) if total_spans > 0 else 0,
            "alerts": len(self.alert_manager.alerts)
        }


# Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ
if __name__ == "__main__":
    print("=" * 60)
    print("Server Init - Iteration 91: Distributed Tracing Platform")
    print("=" * 60)
    
    async def demo():
        platform = DistributedTracingPlatform()
        print("âœ“ Distributed Tracing Platform created")
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ñ€ĞµĞ¹ÑĞµÑ€Ğ¾Ğ²
        print("\nğŸ“¦ Creating Service Tracers...")
        
        services = ["api-gateway", "user-service", "order-service", "payment-service", "notification-service"]
        
        for service in services:
            tracer = platform.create_tracer(service, "1.0.0")
            print(f"  âœ“ {service} tracer created")
            
        # Context Propagation
        print("\nğŸ”„ Context Propagation Demo...")
        
        tracer = platform.tracers["api-gateway"]
        propagator = tracer.propagator
        
        span = tracer.start_span("incoming_request", kind=SpanKind.SERVER)
        span.context.baggage["user_id"] = "user_123"
        span.context.baggage["request_id"] = "req_abc"
        
        headers = propagator.inject(span.context)
        print(f"\n  Injected Headers:")
        for k, v in headers.items():
            print(f"    {k}: {v}")
            
        extracted = propagator.extract(headers)
        print(f"\n  Extracted Context:")
        print(f"    Trace ID: {extracted.trace_id}")
        print(f"    Span ID: {extracted.span_id}")
        print(f"    Baggage: {extracted.baggage}")
        
        await tracer.end_span(span)
        
        # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²
        print("\nğŸ”€ Simulating Distributed Calls...")
        
        call_scenarios = [
            (["api-gateway", "user-service", "notification-service"], 
             ["GET /users", "get_user", "send_email"]),
            (["api-gateway", "order-service", "payment-service", "notification-service"],
             ["POST /orders", "create_order", "process_payment", "send_confirmation"]),
            (["api-gateway", "user-service"],
             ["GET /profile", "get_profile"]),
            (["api-gateway", "order-service", "user-service", "payment-service"],
             ["GET /orders/{id}", "get_order", "get_user", "get_payment_status"]),
        ]
        
        trace_ids = []
        for services_list, operations in call_scenarios:
            trace_id = await platform.simulate_distributed_call(services_list, operations)
            trace_ids.append(trace_id)
            print(f"  âœ“ Trace: {trace_id[:16]}... ({len(services_list)} spans)")
            
        # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
        print("\n  Running additional simulations...")
        for _ in range(20):
            scenario = random.choice(call_scenarios)
            await platform.simulate_distributed_call(scenario[0], scenario[1])
            
        print("  âœ“ 20 additional traces generated")
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚Ñ€ĞµĞ¹ÑĞ°
        print("\nğŸ“Š Trace Analysis...")
        
        trace = platform.aggregator.build_trace(trace_ids[1])
        
        if trace:
            print(f"\n  Trace ID: {trace.trace_id}")
            print(f"  Spans: {trace.span_count}")
            print(f"  Services: {trace.service_count}")
            print(f"  Duration: {trace.duration_ms:.2f}ms")
            print(f"  Has Errors: {trace.has_errors}")
            
            print("\n  Span Tree:")
            
            # Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ Ğ´ĞµÑ€ĞµĞ²Ğ¾
            span_map = {s.context.span_id: s for s in trace.spans}
            
            for span in trace.spans:
                depth = 0
                parent_id = span.context.parent_span_id
                while parent_id:
                    depth += 1
                    parent = span_map.get(parent_id)
                    parent_id = parent.context.parent_span_id if parent else None
                    
                status_icon = "âœ…" if span.status == SpanStatus.OK else "âŒ"
                indent = "  " * depth
                print(f"    {indent}{status_icon} {span.service_name}:{span.name} ({span.duration_ms:.1f}ms)")
                
        # Service Map
        print("\nğŸ—ºï¸ Service Map:")
        
        for service_name, service_info in platform.service_map.services.items():
            print(f"\n  ğŸ“¦ {service_name}")
            print(f"     Total Spans: {service_info.total_spans}")
            print(f"     Error Count: {service_info.error_count}")
            
            if service_info.operations:
                top_ops = sorted(service_info.operations.items(), key=lambda x: -x[1])[:3]
                print(f"     Top Operations: {', '.join(f'{op}({cnt})' for op, cnt in top_ops)}")
                
        # Service Connections
        print("\nğŸ”— Service Connections:")
        
        for edge_key, edge in platform.service_map.edges.items():
            error_rate = (edge.error_count / edge.call_count * 100) if edge.call_count > 0 else 0
            print(f"  {edge.source} â†’ {edge.target}")
            print(f"     Calls: {edge.call_count}, Avg Latency: {edge.avg_latency_ms:.1f}ms, Errors: {error_rate:.1f}%")
            
        # Latency Analysis
        print("\nâ±ï¸ Latency Analysis:")
        
        for key, histogram in platform.latency_analyzer.histograms.items():
            if histogram.total_count >= 5:
                percentiles = platform.latency_analyzer.get_percentiles(*key.split(":"))
                print(f"\n  {key}")
                print(f"     Avg: {histogram.avg_ms:.1f}ms")
                if percentiles:
                    print(f"     p50: {percentiles.get('p50', 0):.1f}ms")
                    print(f"     p95: {percentiles.get('p95', 0):.1f}ms")
                    print(f"     p99: {percentiles.get('p99', 0):.1f}ms")
                    
        # Root Cause Analysis
        print("\nğŸ” Root Cause Analysis:")
        
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ñ€ĞµĞ¹Ñ Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¾Ğ¹
        error_trace = None
        for trace_id in trace_ids:
            trace = platform.aggregator.get_trace(trace_id)
            if trace and trace.has_errors:
                error_trace = trace
                break
                
        if error_trace:
            analysis = platform.root_cause_analyzer.analyze_error_trace(error_trace)
            
            if analysis["root_cause_span"]:
                span = analysis["root_cause_span"]
                print(f"\n  Root Cause Span:")
                print(f"    Service: {span.service_name}")
                print(f"    Operation: {span.name}")
                print(f"    Error: {span.error_message}")
                
            if analysis["error_path"]:
                print(f"\n  Error Path:")
                for step in analysis["error_path"]:
                    print(f"    â†’ {step}")
                    
            if analysis["suggestions"]:
                print(f"\n  Suggestions:")
                for suggestion in analysis["suggestions"]:
                    print(f"    ğŸ’¡ {suggestion}")
        else:
            print("  No error traces found")
            
        # Alerts
        print("\nğŸš¨ Alerts:")
        
        if platform.alert_manager.alerts:
            for alert in platform.alert_manager.alerts[:5]:
                severity_icon = {
                    AlertSeverity.INFO: "â„¹ï¸",
                    AlertSeverity.WARNING: "âš ï¸",
                    AlertSeverity.ERROR: "âŒ",
                    AlertSeverity.CRITICAL: "ğŸ”¥"
                }.get(alert.severity, "?")
                
                print(f"\n  {severity_icon} {alert.title}")
                print(f"     Service: {alert.service}")
                print(f"     Trace: {alert.trace_id[:16]}...")
        else:
            print("  No alerts triggered")
            
        # Statistics
        print("\nğŸ“ˆ Platform Statistics:")
        
        stats = platform.get_statistics()
        
        print(f"\n  Total Traces: {stats['total_traces']}")
        print(f"  Total Spans: {stats['total_spans']}")
        print(f"  Services: {stats['services']}")
        print(f"  Service Connections: {stats['edges']}")
        print(f"  Error Spans: {stats['error_spans']}")
        print(f"  Error Rate: {stats['error_rate']:.1f}%")
        print(f"  Alerts: {stats['alerts']}")
        
        # Dashboard
        print("\nğŸ“‹ Tracing Dashboard:")
        print("  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("  â”‚            Distributed Tracing Overview                     â”‚")
        print("  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"  â”‚ Traces:    {stats['total_traces']:>6}     â”‚  Spans:    {stats['total_spans']:>6}         â”‚")
        print(f"  â”‚ Services:  {stats['services']:>6}     â”‚  Edges:    {stats['edges']:>6}         â”‚")
        print(f"  â”‚ Errors:    {stats['error_spans']:>6}     â”‚  Rate:     {stats['error_rate']:>5.1f}%         â”‚")
        print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
    asyncio.run(demo())
    
    print("\n" + "=" * 60)
    print("Distributed Tracing Platform initialized!")
    print("=" * 60)
