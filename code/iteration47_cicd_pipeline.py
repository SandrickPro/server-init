#!/usr/bin/env python3
"""
Server Init - Iteration 47: CI/CD Pipeline Engine
CI/CD Pipeline –¥–≤–∏–∂–æ–∫

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- Pipeline Definition - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
- Stage & Job Management - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–¥–∏—è–º–∏ –∏ –∑–∞–¥–∞—á–∞–º–∏
- Parallel Execution - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
- Artifact Management - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏
- Build Cache - –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–±–æ—Ä–∫–∏
- Environment Management - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è–º–∏
- Deployment Strategies - —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–µ–ø–ª–æ—è
- Pipeline Analytics - –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
"""

import json
import asyncio
import hashlib
import time
import os
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Set, Callable, Tuple
from enum import Enum
from abc import ABC, abstractmethod
import random
from collections import defaultdict
import uuid


class PipelineStatus(Enum):
    """–°—Ç–∞—Ç—É—Å –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    CANCELED = "canceled"
    SKIPPED = "skipped"
    MANUAL = "manual"


class JobStatus(Enum):
    """–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏"""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    CANCELED = "canceled"
    SKIPPED = "skipped"
    MANUAL = "manual"


class TriggerType(Enum):
    """–¢–∏–ø —Ç—Ä–∏–≥–≥–µ—Ä–∞"""
    PUSH = "push"
    PULL_REQUEST = "pull_request"
    MERGE = "merge"
    SCHEDULE = "schedule"
    MANUAL = "manual"
    API = "api"
    TAG = "tag"


class DeploymentStrategy(Enum):
    """–°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–µ–ø–ª–æ—è"""
    ROLLING = "rolling"
    BLUE_GREEN = "blue_green"
    CANARY = "canary"
    RECREATE = "recreate"
    A_B_TESTING = "a_b_testing"


class RunnerType(Enum):
    """–¢–∏–ø —Ä–∞–Ω–Ω–µ—Ä–∞"""
    DOCKER = "docker"
    KUBERNETES = "kubernetes"
    SHELL = "shell"
    VM = "vm"


@dataclass
class Variable:
    """–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è"""
    key: str
    value: str
    masked: bool = False
    protected: bool = False
    environment: Optional[str] = None


@dataclass
class Artifact:
    """–ê—Ä—Ç–µ—Ñ–∞–∫—Ç —Å–±–æ—Ä–∫–∏"""
    artifact_id: str
    name: str
    path: str
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    size: int = 0
    expire_at: Optional[datetime] = None
    
    # –°–≤—è–∑–∏
    job_id: str = ""
    pipeline_id: str = ""


@dataclass
class Cache:
    """–ö—ç—à —Å–±–æ—Ä–∫–∏"""
    cache_id: str
    key: str
    paths: List[str] = field(default_factory=list)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    size: int = 0
    created_at: datetime = field(default_factory=datetime.now)
    last_used: datetime = field(default_factory=datetime.now)
    
    # –ü–æ–ª–∏—Ç–∏–∫–∞
    policy: str = "pull-push"  # pull, push, pull-push


@dataclass
class JobLog:
    """–õ–æ–≥ –∑–∞–¥–∞—á–∏"""
    entries: List[Dict[str, Any]] = field(default_factory=list)
    
    def append(self, message: str, level: str = "info"):
        self.entries.append({
            "timestamp": datetime.now().isoformat(),
            "level": level,
            "message": message
        })


@dataclass
class Job:
    """–ó–∞–¥–∞—á–∞ CI/CD"""
    job_id: str
    name: str
    stage: str
    
    # –°–∫—Ä–∏–ø—Ç
    script: List[str] = field(default_factory=list)
    before_script: List[str] = field(default_factory=list)
    after_script: List[str] = field(default_factory=list)
    
    # –û–∫—Ä—É–∂–µ–Ω–∏–µ
    image: str = ""
    services: List[str] = field(default_factory=list)
    
    # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    needs: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    
    # –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
    artifacts: List[Artifact] = field(default_factory=list)
    artifact_paths: List[str] = field(default_factory=list)
    
    # –ö—ç—à
    cache: Optional[Cache] = None
    
    # –ü—Ä–∞–≤–∏–ª–∞
    rules: List[Dict[str, Any]] = field(default_factory=list)
    only: List[str] = field(default_factory=list)
    except_: List[str] = field(default_factory=list)
    
    # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    variables: Dict[str, str] = field(default_factory=dict)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    allow_failure: bool = False
    timeout: int = 3600  # seconds
    retry: int = 0
    parallel: int = 1
    when: str = "on_success"  # on_success, on_failure, always, manual
    
    # –°–æ—Å—Ç–æ—è–Ω–∏–µ
    status: JobStatus = JobStatus.PENDING
    started_at: Optional[datetime] = None
    finished_at: Optional[datetime] = None
    duration: float = 0.0
    
    # –†–∞–Ω–Ω–µ—Ä
    runner_id: Optional[str] = None
    
    # –õ–æ–≥–∏
    log: JobLog = field(default_factory=JobLog)


@dataclass
class Stage:
    """–°—Ç–∞–¥–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    name: str
    jobs: List[Job] = field(default_factory=list)
    
    # –°–æ—Å—Ç–æ—è–Ω–∏–µ
    status: PipelineStatus = PipelineStatus.PENDING
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    needs_approval: bool = False
    approved_by: Optional[str] = None


@dataclass
class Pipeline:
    """CI/CD Pipeline"""
    pipeline_id: str
    name: str
    
    # –ò—Å—Ç–æ—á–Ω–∏–∫
    project: str = ""
    ref: str = "main"
    sha: str = ""
    
    # –¢—Ä–∏–≥–≥–µ—Ä
    trigger_type: TriggerType = TriggerType.PUSH
    triggered_by: str = ""
    
    # –°—Ç–∞–¥–∏–∏
    stages: List[Stage] = field(default_factory=list)
    
    # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    variables: Dict[str, Variable] = field(default_factory=dict)
    
    # –°–æ—Å—Ç–æ—è–Ω–∏–µ
    status: PipelineStatus = PipelineStatus.PENDING
    
    # –í—Ä–µ–º—è
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    finished_at: Optional[datetime] = None
    duration: float = 0.0
    
    # –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
    artifacts: List[Artifact] = field(default_factory=list)
    
    # URL
    web_url: str = ""


@dataclass
class Environment:
    """–û–∫—Ä—É–∂–µ–Ω–∏–µ –¥–µ–ø–ª–æ—è"""
    env_id: str
    name: str
    
    # URL
    external_url: str = ""
    
    # –°–æ—Å—Ç–æ—è–Ω–∏–µ
    state: str = "available"  # available, stopped
    
    # –î–µ–ø–ª–æ–π–º–µ–Ω—Ç
    last_deployment_id: Optional[str] = None
    deployed_at: Optional[datetime] = None
    
    # –ó–∞—â–∏—Ç–∞
    protected: bool = False
    required_approval: bool = False


@dataclass
class Deployment:
    """–î–µ–ø–ª–æ–π–º–µ–Ω—Ç"""
    deployment_id: str
    environment: str
    
    # –ü–∞–π–ø–ª–∞–π–Ω
    pipeline_id: str = ""
    job_id: str = ""
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è
    strategy: DeploymentStrategy = DeploymentStrategy.ROLLING
    
    # –°–æ—Å—Ç–æ—è–Ω–∏–µ
    status: str = "created"  # created, running, success, failed, canceled
    
    # –í—Ä–µ–º—è
    created_at: datetime = field(default_factory=datetime.now)
    deployed_at: Optional[datetime] = None
    
    # Rollback
    rollback_to: Optional[str] = None


@dataclass
class Runner:
    """CI/CD Runner"""
    runner_id: str
    name: str
    
    # –¢–∏–ø
    runner_type: RunnerType = RunnerType.DOCKER
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    executor: str = "docker"
    tags: List[str] = field(default_factory=list)
    
    # –°–æ—Å—Ç–æ—è–Ω–∏–µ
    status: str = "online"  # online, offline, paused
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    jobs_count: int = 0
    current_job: Optional[str] = None
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    registered_at: datetime = field(default_factory=datetime.now)
    last_contact: datetime = field(default_factory=datetime.now)


class PipelineParser:
    """–ü–∞—Ä—Å–µ—Ä –ø–∞–π–ø–ª–∞–π–Ω–æ–≤"""
    
    def parse_yaml(self, config: Dict[str, Any]) -> Pipeline:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        pipeline = Pipeline(
            pipeline_id=f"pipeline_{uuid.uuid4().hex[:8]}",
            name=config.get("name", "pipeline")
        )
        
        # –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞–¥–∏–π
        stage_names = config.get("stages", ["build", "test", "deploy"])
        stages: Dict[str, Stage] = {}
        
        for stage_name in stage_names:
            stages[stage_name] = Stage(name=stage_name)
            
        # –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–¥–∞—á
        for job_name, job_config in config.items():
            if job_name in ["stages", "variables", "default", "workflow"]:
                continue
                
            if not isinstance(job_config, dict):
                continue
                
            stage_name = job_config.get("stage", "test")
            
            job = Job(
                job_id=f"job_{uuid.uuid4().hex[:8]}",
                name=job_name,
                stage=stage_name,
                script=job_config.get("script", []),
                before_script=job_config.get("before_script", []),
                after_script=job_config.get("after_script", []),
                image=job_config.get("image", ""),
                needs=job_config.get("needs", []),
                variables=job_config.get("variables", {}),
                allow_failure=job_config.get("allow_failure", False),
                when=job_config.get("when", "on_success"),
                artifact_paths=job_config.get("artifacts", {}).get("paths", [])
            )
            
            if stage_name in stages:
                stages[stage_name].jobs.append(job)
                
        pipeline.stages = list(stages.values())
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        for key, value in config.get("variables", {}).items():
            pipeline.variables[key] = Variable(key=key, value=str(value))
            
        return pipeline


class JobExecutor:
    """–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –∑–∞–¥–∞—á"""
    
    def __init__(self):
        self.runners: Dict[str, Runner] = {}
        
    def register_runner(self, runner: Runner):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–Ω–Ω–µ—Ä–∞"""
        self.runners[runner.runner_id] = runner
        
    def find_available_runner(self, job: Job) -> Optional[Runner]:
        """–ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Ä–∞–Ω–Ω–µ—Ä–∞"""
        for runner in self.runners.values():
            if runner.status == "online" and not runner.current_job:
                return runner
        return None
        
    async def execute_job(self, job: Job, 
                           variables: Dict[str, Variable]) -> JobStatus:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        runner = self.find_available_runner(job)
        
        if not runner:
            job.log.append("No available runner", "warning")
            return JobStatus.PENDING
            
        job.runner_id = runner.runner_id
        runner.current_job = job.job_id
        runner.jobs_count += 1
        
        job.status = JobStatus.RUNNING
        job.started_at = datetime.now()
        
        job.log.append(f"Job started on runner {runner.name}", "info")
        
        try:
            # Before script
            for cmd in job.before_script:
                job.log.append(f"$ {cmd}", "info")
                await asyncio.sleep(0.02)
                
            # Main script
            for cmd in job.script:
                job.log.append(f"$ {cmd}", "info")
                await asyncio.sleep(0.05)
                
                # –°–∏–º—É–ª—è—Ü–∏—è –≤—ã–≤–æ–¥–∞ –∫–æ–º–∞–Ω–¥—ã
                job.log.append(f"Output: executed {cmd}", "info")
                
            # After script
            for cmd in job.after_script:
                job.log.append(f"$ {cmd}", "info")
                await asyncio.sleep(0.02)
                
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
            for path in job.artifact_paths:
                artifact = Artifact(
                    artifact_id=f"artifact_{uuid.uuid4().hex[:8]}",
                    name=os.path.basename(path),
                    path=path,
                    job_id=job.job_id,
                    size=random.randint(1000, 1000000)
                )
                job.artifacts.append(artifact)
                job.log.append(f"Artifact created: {path}", "info")
                
            job.status = JobStatus.SUCCESS
            job.log.append("Job succeeded", "info")
            
        except Exception as e:
            job.status = JobStatus.FAILED
            job.log.append(f"Job failed: {str(e)}", "error")
            
        finally:
            job.finished_at = datetime.now()
            job.duration = (job.finished_at - job.started_at).total_seconds()
            runner.current_job = None
            
        return job.status


class PipelineEngine:
    """–î–≤–∏–∂–æ–∫ CI/CD Pipeline"""
    
    def __init__(self):
        self.pipelines: Dict[str, Pipeline] = {}
        self.parser = PipelineParser()
        self.executor = JobExecutor()
        self.environments: Dict[str, Environment] = {}
        self.deployments: Dict[str, Deployment] = {}
        
        # –ö—ç—à
        self.cache_store: Dict[str, Cache] = {}
        
        # –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
        self.artifact_store: Dict[str, Artifact] = {}
        
        # –ò—Å—Ç–æ—Ä–∏—è
        self.pipeline_history: List[Dict[str, Any]] = []
        
    def create_pipeline(self, config: Dict[str, Any],
                         project: str = "",
                         ref: str = "main",
                         trigger_type: TriggerType = TriggerType.PUSH) -> Pipeline:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        pipeline = self.parser.parse_yaml(config)
        pipeline.project = project
        pipeline.ref = ref
        pipeline.sha = hashlib.sha256(str(time.time()).encode()).hexdigest()[:8]
        pipeline.trigger_type = trigger_type
        
        self.pipelines[pipeline.pipeline_id] = pipeline
        
        return pipeline
        
    async def run_pipeline(self, pipeline_id: str) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        pipeline = self.pipelines.get(pipeline_id)
        if not pipeline:
            return {"error": "Pipeline not found"}
            
        pipeline.status = PipelineStatus.RUNNING
        pipeline.started_at = datetime.now()
        
        results = {
            "pipeline_id": pipeline_id,
            "stages": []
        }
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç–∞–¥–∏–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        for stage in pipeline.stages:
            stage_result = await self._run_stage(stage, pipeline)
            results["stages"].append(stage_result)
            
            if stage.status == PipelineStatus.FAILED:
                pipeline.status = PipelineStatus.FAILED
                break
                
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        if pipeline.status == PipelineStatus.RUNNING:
            pipeline.status = PipelineStatus.SUCCESS
            
        pipeline.finished_at = datetime.now()
        pipeline.duration = (pipeline.finished_at - pipeline.started_at).total_seconds()
        
        # –°–±–æ—Ä –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        for stage in pipeline.stages:
            for job in stage.jobs:
                pipeline.artifacts.extend(job.artifacts)
                
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.pipeline_history.append({
            "pipeline_id": pipeline_id,
            "status": pipeline.status.value,
            "duration": pipeline.duration,
            "timestamp": datetime.now().isoformat()
        })
        
        results["status"] = pipeline.status.value
        results["duration"] = pipeline.duration
        
        return results
        
    async def _run_stage(self, stage: Stage, 
                          pipeline: Pipeline) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç–∞–¥–∏–∏"""
        stage.status = PipelineStatus.RUNNING
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–¥–∞—á –ø–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º
        jobs_without_deps = [j for j in stage.jobs if not j.needs]
        jobs_with_deps = [j for j in stage.jobs if j.needs]
        
        results = {
            "stage": stage.name,
            "jobs": []
        }
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –∑–∞–¥–∞—á
        if jobs_without_deps:
            tasks = [
                self.executor.execute_job(job, pipeline.variables)
                for job in jobs_without_deps
            ]
            await asyncio.gather(*tasks)
            
            for job in jobs_without_deps:
                results["jobs"].append({
                    "name": job.name,
                    "status": job.status.value,
                    "duration": job.duration
                })
                
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
        for job in jobs_with_deps:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            deps_ok = all(
                self._get_job_by_name(stage, dep).status == JobStatus.SUCCESS
                for dep in job.needs
                if self._get_job_by_name(stage, dep)
            )
            
            if deps_ok:
                await self.executor.execute_job(job, pipeline.variables)
            else:
                job.status = JobStatus.SKIPPED
                
            results["jobs"].append({
                "name": job.name,
                "status": job.status.value,
                "duration": job.duration
            })
            
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å—Ç–∞–¥–∏–∏
        failed_jobs = [j for j in stage.jobs if j.status == JobStatus.FAILED and not j.allow_failure]
        
        if failed_jobs:
            stage.status = PipelineStatus.FAILED
        else:
            stage.status = PipelineStatus.SUCCESS
            
        results["status"] = stage.status.value
        
        return results
        
    def _get_job_by_name(self, stage: Stage, name: str) -> Optional[Job]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –ø–æ –∏–º–µ–Ω–∏"""
        for job in stage.jobs:
            if job.name == name:
                return job
        return None
        
    async def cancel_pipeline(self, pipeline_id: str) -> bool:
        """–û—Ç–º–µ–Ω–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        pipeline = self.pipelines.get(pipeline_id)
        if not pipeline:
            return False
            
        pipeline.status = PipelineStatus.CANCELED
        pipeline.finished_at = datetime.now()
        
        for stage in pipeline.stages:
            if stage.status == PipelineStatus.RUNNING:
                stage.status = PipelineStatus.CANCELED
                for job in stage.jobs:
                    if job.status == JobStatus.RUNNING:
                        job.status = JobStatus.CANCELED
                        
        return True
        
    async def retry_pipeline(self, pipeline_id: str) -> Optional[str]:
        """–ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        old_pipeline = self.pipelines.get(pipeline_id)
        if not old_pipeline:
            return None
            
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ä–æ–≥–æ
        new_pipeline = Pipeline(
            pipeline_id=f"pipeline_{uuid.uuid4().hex[:8]}",
            name=old_pipeline.name,
            project=old_pipeline.project,
            ref=old_pipeline.ref,
            trigger_type=TriggerType.API,
            stages=old_pipeline.stages  # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞–¥–∏–π –Ω—É–∂–Ω–æ
        )
        
        self.pipelines[new_pipeline.pipeline_id] = new_pipeline
        
        return new_pipeline.pipeline_id
        
    def create_environment(self, name: str, 
                            external_url: str = "") -> Environment:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        env = Environment(
            env_id=f"env_{uuid.uuid4().hex[:8]}",
            name=name,
            external_url=external_url
        )
        
        self.environments[env.env_id] = env
        
        return env
        
    async def deploy(self, pipeline_id: str, environment: str,
                      strategy: DeploymentStrategy = DeploymentStrategy.ROLLING) -> Deployment:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–ø–ª–æ–π–º–µ–Ω—Ç–∞"""
        deployment = Deployment(
            deployment_id=f"deploy_{uuid.uuid4().hex[:8]}",
            environment=environment,
            pipeline_id=pipeline_id,
            strategy=strategy
        )
        
        deployment.status = "running"
        
        # –°–∏–º—É–ª—è—Ü–∏—è –¥–µ–ø–ª–æ—è
        await asyncio.sleep(0.2)
        
        deployment.status = "success"
        deployment.deployed_at = datetime.now()
        
        self.deployments[deployment.deployment_id] = deployment
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        for env in self.environments.values():
            if env.name == environment:
                env.last_deployment_id = deployment.deployment_id
                env.deployed_at = deployment.deployed_at
                break
                
        return deployment
        
    async def rollback(self, deployment_id: str) -> Optional[Deployment]:
        """–û—Ç–∫–∞—Ç –¥–µ–ø–ª–æ–π–º–µ–Ω—Ç–∞"""
        deployment = self.deployments.get(deployment_id)
        if not deployment:
            return None
            
        # –ü–æ–∏—Å–∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ –¥–µ–ø–ª–æ–π–º–µ–Ω—Ç–∞
        env_deployments = [
            d for d in self.deployments.values()
            if d.environment == deployment.environment
            and d.status == "success"
            and d.deployment_id != deployment_id
        ]
        
        if not env_deployments:
            return None
            
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π —É—Å–ø–µ—à–Ω—ã–π
        previous = max(env_deployments, key=lambda x: x.deployed_at or datetime.min)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ rollback deployment
        rollback = Deployment(
            deployment_id=f"deploy_{uuid.uuid4().hex[:8]}",
            environment=deployment.environment,
            rollback_to=previous.deployment_id
        )
        
        rollback.status = "running"
        await asyncio.sleep(0.1)
        rollback.status = "success"
        rollback.deployed_at = datetime.now()
        
        self.deployments[rollback.deployment_id] = rollback
        
        return rollback
        
    def get_pipeline_analytics(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤"""
        total = len(self.pipeline_history)
        
        if total == 0:
            return {"total": 0}
            
        success = len([p for p in self.pipeline_history if p["status"] == "success"])
        failed = len([p for p in self.pipeline_history if p["status"] == "failed"])
        
        durations = [p["duration"] for p in self.pipeline_history if p["duration"] > 0]
        avg_duration = sum(durations) / len(durations) if durations else 0
        
        return {
            "total": total,
            "success": success,
            "failed": failed,
            "success_rate": round(success / total * 100, 2) if total > 0 else 0,
            "average_duration": round(avg_duration, 2),
            "pipelines_per_day": len([
                p for p in self.pipeline_history
                if datetime.fromisoformat(p["timestamp"]).date() == datetime.now().date()
            ])
        }
        
    def get_statistics(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        return {
            "pipelines": len(self.pipelines),
            "environments": len(self.environments),
            "deployments": len(self.deployments),
            "runners": len(self.executor.runners),
            "online_runners": len([
                r for r in self.executor.runners.values()
                if r.status == "online"
            ]),
            "cached_items": len(self.cache_store),
            "artifacts": len(self.artifact_store)
        }


# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è
if __name__ == "__main__":
    print("=" * 60)
    print("Server Init - Iteration 47: CI/CD Pipeline Engine")
    print("=" * 60)
    
    async def demo():
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–≤–∏–∂–∫–∞
        engine = PipelineEngine()
        print("‚úì CI/CD Pipeline Engine created")
        
        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–Ω–Ω–µ—Ä–æ–≤
        print("\nüñ•Ô∏è Registering runners...")
        
        runner1 = Runner(
            runner_id="runner_001",
            name="docker-runner-1",
            runner_type=RunnerType.DOCKER,
            tags=["docker", "linux"]
        )
        engine.executor.register_runner(runner1)
        print(f"  ‚úì Registered: {runner1.name}")
        
        runner2 = Runner(
            runner_id="runner_002",
            name="docker-runner-2",
            runner_type=RunnerType.DOCKER,
            tags=["docker", "linux"]
        )
        engine.executor.register_runner(runner2)
        print(f"  ‚úì Registered: {runner2.name}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏–π
        print("\nüåç Creating environments...")
        
        staging = engine.create_environment(
            name="staging",
            external_url="https://staging.example.com"
        )
        print(f"  ‚úì Created: {staging.name}")
        
        production = engine.create_environment(
            name="production",
            external_url="https://example.com"
        )
        production.protected = True
        production.required_approval = True
        print(f"  ‚úì Created: {production.name} (protected)")
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        pipeline_config = {
            "name": "web-app-pipeline",
            "stages": ["build", "test", "deploy"],
            "variables": {
                "DOCKER_IMAGE": "myapp:latest",
                "NODE_ENV": "production"
            },
            "build": {
                "stage": "build",
                "image": "node:18",
                "script": [
                    "npm install",
                    "npm run build"
                ],
                "artifacts": {
                    "paths": ["dist/", "node_modules/"]
                }
            },
            "unit-tests": {
                "stage": "test",
                "image": "node:18",
                "needs": ["build"],
                "script": [
                    "npm run test:unit"
                ]
            },
            "integration-tests": {
                "stage": "test",
                "image": "node:18",
                "needs": ["build"],
                "script": [
                    "npm run test:integration"
                ],
                "allow_failure": True
            },
            "deploy-staging": {
                "stage": "deploy",
                "image": "kubectl:latest",
                "script": [
                    "kubectl apply -f k8s/staging/"
                ],
                "when": "on_success"
            }
        }
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
        print("\nüöÄ Creating pipeline...")
        
        pipeline = engine.create_pipeline(
            config=pipeline_config,
            project="web-app",
            ref="main",
            trigger_type=TriggerType.PUSH
        )
        print(f"  Pipeline ID: {pipeline.pipeline_id}")
        print(f"  Stages: {[s.name for s in pipeline.stages]}")
        print(f"  Jobs: {sum(len(s.jobs) for s in pipeline.stages)}")
        
        # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
        print("\n‚ñ∂Ô∏è Running pipeline...")
        
        result = await engine.run_pipeline(pipeline.pipeline_id)
        
        print(f"\nüìä Pipeline Results:")
        print(f"  Status: {result['status']}")
        print(f"  Duration: {result['duration']:.2f}s")
        
        for stage_result in result["stages"]:
            print(f"\n  Stage: {stage_result['stage']} ({stage_result['status']})")
            for job in stage_result["jobs"]:
                status_icon = "‚úì" if job["status"] == "success" else "‚úó"
                print(f"    {status_icon} {job['name']}: {job['status']} ({job['duration']:.2f}s)")
                
        # –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
        print("\nüìù Job Logs (build):")
        
        for stage in pipeline.stages:
            for job in stage.jobs:
                if job.name == "build":
                    for entry in job.log.entries[:5]:
                        print(f"    [{entry['level']}] {entry['message']}")
                        
        # –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
        print("\nüì¶ Pipeline Artifacts:")
        
        for artifact in pipeline.artifacts[:3]:
            print(f"  - {artifact.name}: {artifact.size} bytes")
            
        # –î–µ–ø–ª–æ–π
        print("\nüö¢ Deploying to staging...")
        
        deployment = await engine.deploy(
            pipeline_id=pipeline.pipeline_id,
            environment="staging",
            strategy=DeploymentStrategy.ROLLING
        )
        print(f"  Deployment ID: {deployment.deployment_id}")
        print(f"  Status: {deployment.status}")
        print(f"  Strategy: {deployment.strategy.value}")
        
        # –í—Ç–æ—Ä–æ–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        print("\nüìà Running more pipelines for analytics...")
        
        for i in range(3):
            p = engine.create_pipeline(
                config=pipeline_config,
                project="web-app",
                ref="main"
            )
            await engine.run_pipeline(p.pipeline_id)
            
        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
        analytics = engine.get_pipeline_analytics()
        print(f"\nüìä Pipeline Analytics:")
        print(f"  Total pipelines: {analytics['total']}")
        print(f"  Success rate: {analytics['success_rate']}%")
        print(f"  Average duration: {analytics['average_duration']}s")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = engine.get_statistics()
        print(f"\nüìà Engine Statistics:")
        print(f"  Pipelines: {stats['pipelines']}")
        print(f"  Environments: {stats['environments']}")
        print(f"  Deployments: {stats['deployments']}")
        print(f"  Runners: {stats['runners']} ({stats['online_runners']} online)")
        
    asyncio.run(demo())
    
    print("\n" + "=" * 60)
    print("CI/CD Pipeline Engine initialized!")
    print("=" * 60)
